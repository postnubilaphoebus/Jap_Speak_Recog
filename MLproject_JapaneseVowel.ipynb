{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Project: Japanese Vowel speaker classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data into time series arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data sets\n",
    "trainData = np.loadtxt(\"ae.train\")\n",
    "testData = np.loadtxt(\"ae.test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview: \n",
    "* Training: 270 (30 utterances by 9 speakers. See file 'size_ae.train'.) \n",
    "* Testing: 370 (24-88 utterances by the same 9 speakers in different opportunities. See file 'size_ae.test'.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining 270 training time series arrays\n",
    "# arrays are (N x 12); where N is length of time series recording and 12 is number of dimensions (ie channels)\n",
    "trainInputs = np.empty((270,1), dtype=object)\n",
    "readindex = 0\n",
    "\n",
    "for i in range(1,271):\n",
    "    readindex = readindex + 1  \n",
    "    l = 0\n",
    "    while trainData[readindex-1, 1] != 1:\n",
    "        l = l + 1 \n",
    "        readindex = readindex + 1\n",
    "    trainInputs[i-1,0] = trainData[readindex-l-1:readindex-1,:]\n",
    "\n",
    "\n",
    "# obtaining 370 test time series arrays \n",
    "# arrays are (N x 12); where N is length of time series recording and 12 is number of dimensions (ie channels)\n",
    "testInputs = np.empty((370,1), dtype=object)\n",
    "readindex = 0\n",
    "\n",
    "# The last 12 entries of each recording are 1s, indicating 12 channels\n",
    "# They are droppped when reading in the data\n",
    "for i in range(1,371):\n",
    "    readindex = readindex + 1\n",
    "    l = 0 \n",
    "    while testData[readindex-1, 1] != 1:\n",
    "        l = l+1 \n",
    "        readindex = readindex + 1\n",
    "    testInputs[i-1,0] = testData[readindex-l-1:readindex-1,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining 270 training outputs (speaker targets)\n",
    "# arrays are (N x 9); where N is length of time series recording and 9 is number of different speakers\n",
    "# the speaker is indicated with a '1'\n",
    "trainOutputs = np.empty((270,1), dtype=object)\n",
    "\n",
    "for i in range(1,271):\n",
    "    l = np.size(trainInputs[i-1,0],0)\n",
    "    teacher = np.zeros((l,9))\n",
    "    speakerIndex = np.ceil(i/30)\n",
    "    teacher[:,np.int(speakerIndex)-1] = 1 \n",
    "    trainOutputs[i-1,0] = teacher\n",
    "\n",
    "# obtaining 370 test outputs (speaker targets)\n",
    "# arrays are (N x 9); where N is length of time series recording and 9 is number of different speakers\n",
    "# the speaker is indicated with a '1'\n",
    "testOutputs = np.empty((370,1), dtype=object)\n",
    "speakerIndex = 1\n",
    "blockCounter = 0\n",
    "blockLengthes = [31, 35, 88, 44, 29, 24, 40, 50, 29]\n",
    "for i in range(1, 371):\n",
    "    blockCounter = blockCounter + 1 \n",
    "    if blockCounter == blockLengthes[speakerIndex-1] + 1:\n",
    "        speakerIndex = speakerIndex + 1\n",
    "        blockCounter = 1\n",
    "    l = np.size(testInputs[i-1,0], 0)\n",
    "    teacher = np.zeros((l,9))\n",
    "    teacher[:,np.int(speakerIndex)-1] = 1   \n",
    "    testOutputs[i-1, 0] = teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prints histogram of timeseries length (exploratory analysis)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "histos = np.zeros(270)\n",
    "\n",
    "for i in range(270):\n",
    "    histos[i] = (len(trainInputs[i, 0]))\n",
    "\n",
    "#print(histos)\n",
    "plt.title('Counting timeseries length (total 270)')\n",
    "plt.xlabel('Timeseries length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(histos, bins = 20, ec='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add length of each recording as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RecordingLength = histos\n",
    "for i in range(270):\n",
    "    RecordingLength[i] = RecordingLength[i] / 26\n",
    "#print(RecordingLength)\n",
    "\n",
    "for i in range(270):\n",
    "    lenArray = len(trainInputs[i][0])\n",
    "    rec = np.full(lenArray, RecordingLength[i])\n",
    "    newArray = np.column_stack((trainInputs[i][0][:], rec))\n",
    "    trainInputs[i][0] = newArray\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing: Subtract minimum value of channel from each value. Finish with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#according to the paper by Dwarampudi et al 2019(in whatsappchat), prepadding is preferred. \n",
    "#However we seem to get better results with postpadding. That's why both are kept for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First: Find minimum of all channels of all samples\n",
    "minimum = np.zeros(13)\n",
    "for sample in trainInputs:\n",
    "    for array in sample[0]:\n",
    "        channelnumber = 0\n",
    "        for number in array:\n",
    "            if number < minimum[channelnumber]:\n",
    "                minimum[channelnumber] = number\n",
    "            channelnumber = channelnumber + 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.783783 -1.852765 -0.745858 -0.957525 -0.691587 -0.83559  -0.616608\n",
      " -0.57128  -0.623201 -0.503843 -0.426728 -0.336968  0.      ]\n"
     ]
    }
   ],
   "source": [
    "print(minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Subtract minimum value from all values per channel\n",
    "trainInputsNonNegative = copy.deepcopy(trainInputs)\n",
    "samplenumber = 0\n",
    "for sample in trainInputsNonNegative:\n",
    "    arraynumber = 0\n",
    "    for array in sample[0]:\n",
    "        channelnumber = 0\n",
    "        for number in array:\n",
    "            trainInputsNonNegative[samplenumber][0][arraynumber][channelnumber] = number - minimum[channelnumber]\n",
    "            channelnumber = channelnumber + 1\n",
    "        arraynumber = arraynumber + 1\n",
    "    samplenumber = samplenumber + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pads the training inputs with zeroes to make all the timeseries of equal length\n",
    "size_max = 13 * 26\n",
    "trainInputsNonNegativePre = np.empty((270,size_max), dtype=object)\n",
    "trainInputsNonNegativePost = np.empty((270,size_max), dtype=object)\n",
    "\n",
    "idx = 0 \n",
    "for element in trainInputsNonNegative:\n",
    "    element = np.ndarray.flatten(element[0])\n",
    "    # Pads zeroes before    \n",
    "    elements = element\n",
    "    elements = np.pad(elements, (size_max - len(elements), 0), 'constant')\n",
    "    trainInputsNonNegativePre[idx] = elements\n",
    "    \n",
    "    # Pads zeroes after\n",
    "    # Pad element with zeroes until it reaches the shape of the largest timeseries (12 * 26 = 312)\n",
    "    shape = np.shape(element)\n",
    "    padded_array = np.zeros(size_max)\n",
    "    padded_array[:shape[0]] = element  \n",
    "    element = padded_array\n",
    "    # print(element)\n",
    "\n",
    "    trainInputsNonNegativePost[idx] = element\n",
    "    idx = idx + 1\n",
    "\n",
    "trainOutputsNew = np.empty((270,1), dtype=object)\n",
    "\n",
    "# Transforms the trainOutputs in classes 1-9\n",
    "idxx = 0\n",
    "for elements in trainOutputs:\n",
    "    for i in range(len(elements[0][0])):\n",
    "       if elements[0][0][i] == 1:\n",
    "           trainOutputsNew[idxx] = i + 1\n",
    "           idxx = idxx + 1\n",
    "        \n",
    "trainOutputsNew = np.ravel(trainOutputsNew)\n",
    "trainOutputsNew = trainOutputsNew.astype('int')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing 2: Put numbers in range 0-1. Finish with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additionally set numbers between 0/1\n",
    "#Find maximum per channel\n",
    "trainInputsZeroOne = copy.deepcopy(trainInputsNonNegative)\n",
    "maximum = np.zeros(13)\n",
    "for sample in trainInputs:\n",
    "    for array in sample[0]:\n",
    "        channelnumber = 0\n",
    "        for number in array:\n",
    "            if number > maximum[channelnumber]:\n",
    "                maximum[channelnumber] = number\n",
    "            channelnumber = channelnumber + 1\n",
    "\n",
    "#divide by maximum value per channel\n",
    "samplenumber = 0\n",
    "for sample in trainInputsZeroOne:\n",
    "    arraynumber = 0\n",
    "    for array in sample[0]:\n",
    "        channelnumber = 0\n",
    "        for number in array:\n",
    "            trainInputsZeroOne[samplenumber][0][arraynumber][channelnumber] = number / maximum[channelnumber]\n",
    "            channelnumber = channelnumber + 1\n",
    "        arraynumber = arraynumber + 1\n",
    "    samplenumber = samplenumber + 1\n",
    "\n",
    "#pad the samples\n",
    "size_max = 13 * 26\n",
    "trainInputsZeroOnePre = np.empty((270,size_max), dtype=object)\n",
    "trainInputsZeroOnePost = np.empty((270,size_max), dtype=object)\n",
    "\n",
    "idx = 0 \n",
    "for element in trainInputsZeroOne:\n",
    "    element = np.ndarray.flatten(element[0])\n",
    "    # Pads zeroes before    \n",
    "    elements = element\n",
    "    elements = np.pad(elements, (size_max - len(elements), 0), 'constant')\n",
    "    trainInputsZeroOnePre[idx] = elements\n",
    "    \n",
    "    # Pads zeroes after\n",
    "    # Pad element with zeroes until it reaches the shape of the largest timeseries (13 * 26 = 338)\n",
    "    shape = np.shape(element)\n",
    "    padded_array = np.zeros(size_max)\n",
    "    padded_array[:shape[0]] = element  \n",
    "    element = padded_array\n",
    "\n",
    "    trainInputsZeroOnePost[idx] = element\n",
    "    idx = idx + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing 3: Induce bias by squaring. Finish with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize/Bias numbers by squaring\n",
    "trainInputsSquared = copy.deepcopy(trainInputsZeroOne)\n",
    "\n",
    "#divide by maximum value per channel\n",
    "samplenumber = 0\n",
    "for sample in trainInputsSquared:\n",
    "    arraynumber = 0\n",
    "    for array in sample[0]:\n",
    "        channelnumber = 0\n",
    "        for number in array:\n",
    "            trainInputsSquared[samplenumber][0][arraynumber][channelnumber] = number *number\n",
    "            channelnumber = channelnumber + 1\n",
    "        arraynumber = arraynumber + 1\n",
    "    samplenumber = samplenumber + 1\n",
    "\n",
    "#pad normalized further samples\n",
    "size_max = 13 * 26\n",
    "trainInputsSquaredPre = np.empty((270,size_max), dtype=object)\n",
    "trainInputsSquaredPost = np.empty((270,size_max), dtype=object)\n",
    "\n",
    "idx = 0 \n",
    "for element in trainInputsSquared:\n",
    "    element = np.ndarray.flatten(element[0])\n",
    "    # Pads zeroes before    \n",
    "    elements = element\n",
    "    elements = np.pad(elements, (size_max - len(elements), 0), 'constant')\n",
    "    trainInputsSquaredPre[idx] = elements\n",
    "    \n",
    "    # Pads zeroes after\n",
    "    # Pad element with zeroes until it reaches the shape of the largest timeseries (13 * 26 = 338)\n",
    "    shape = np.shape(element)\n",
    "    padded_array = np.zeros(size_max)\n",
    "    padded_array[:shape[0]] = element  \n",
    "    element = padded_array\n",
    "\n",
    "    trainInputsSquaredPost[idx] = element\n",
    "    idx = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length inputs_train: 216\n",
      "Length outputs_train: 216\n",
      "Length inputs_test: 270\n",
      "Length trainOutputsNew: 270\n"
     ]
    }
   ],
   "source": [
    "# Crossvalidation. Currently only splitting in train-test data. Ideally, we want a validation set as well (e.g. 80 - 10 - 10 or 60 - 20 - 20)\n",
    "# Function taken from my Intro to Data Science assignment 3 code\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def splitData(inputs, outputs):   \n",
    "    # To avoid overfitting, we divide the dataset into a part for training and a part for testing\n",
    "    # We split the dataset into 80% training data and 20% testing data\n",
    "    inputs_train, inputs_test, outputs_train, outputs_test = train_test_split(\n",
    "            inputs, outputs, test_size=0.20) \n",
    "    \n",
    "    return inputs_train, inputs_test, outputs_train, outputs_test\n",
    "\n",
    "inputs_train, inputs_test, outputs_train, outputs_test = splitData(trainInputsNonNegative, trainOutputsNew)\n",
    "\n",
    "print('Length inputs_train:', len(inputs_train))\n",
    "print('Length outputs_train:', len(outputs_train))\n",
    "print('Length inputs_test:', len(trainOutputsNew))\n",
    "print('Length trainOutputsNew:', len(trainOutputsNew))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy NonNegativePre: 93.03703703703704\n",
      "Average accuracy NonNegativePost: 93.66666666666669\n",
      "Average accuracy ZeroOnePre: 94.46296296296296\n",
      "Average accuracy ZeroOnePost: 92.29629629629632\n",
      "Average accuracy SquaredPre: 91.55555555555554\n",
      "Average accuracy SquaredPost: 88.33333333333331\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Implementation Support Vector Machine\n",
    "def SVM(inputs_train, outputs_train, inputs_test):    \n",
    "    # Create a classifier \n",
    "    classifier = svm.SVC(kernel='linear')    \n",
    "    outputs_train = outputs_train.astype('int')\n",
    "    classifier.fit(inputs_train, outputs_train)\n",
    "    \n",
    "    # Predict the test data\n",
    "    labels_prediction = classifier.predict(inputs_test)\n",
    "\n",
    "    return labels_prediction\n",
    "\n",
    "def predictLabels(trainInputs, trainOutputs):\n",
    "    inputs_train, inputs_test, outputs_train, outputs_test = splitData(trainInputs, trainOutputs)\n",
    "\n",
    "    # Predict the test labels\n",
    "    prediction = SVM(inputs_train, outputs_train, inputs_test)\n",
    "\n",
    "    # Print results\n",
    "    wrong = 0\n",
    "    length = len(prediction)\n",
    "    for i in range(length):\n",
    "        #print(prediction[i], np.ravel(outputs_test)[i])\n",
    "        if(prediction[i] != np.ravel(outputs_test)[i]):\n",
    "            wrong = wrong + 1\n",
    "\n",
    "    return ((length - wrong) / length) * 100\n",
    "\n",
    "#Pre is for prepadded, Post for postpadded\n",
    "accuracy_NonNegativePre = np.zeros(100)\n",
    "accuracy_NonNegativePost = np.zeros(100)\n",
    "accuracy_ZeroOnePre = np.zeros(100)\n",
    "accuracy_ZeroOnePost = np.zeros(100)\n",
    "accuracy_SquaredPre = np.zeros(100)\n",
    "accuracy_SquaredPost = np.zeros(100)\n",
    "for j in range(100):\n",
    "    accuracy_NonNegativePre[j] = predictLabels(trainInputsNonNegativePre, trainOutputsNew)\n",
    "    accuracy_NonNegativePost[j] = predictLabels(trainInputsNonNegativePost, trainOutputsNew)\n",
    "    accuracy_ZeroOnePre[j] = predictLabels(trainInputsZeroOnePre, trainOutputsNew)\n",
    "    accuracy_ZeroOnePost[j] = predictLabels(trainInputsZeroOnePost, trainOutputsNew)\n",
    "    accuracy_SquaredPre[j] = predictLabels(trainInputsSquaredPre, trainOutputsNew)\n",
    "    accuracy_SquaredPost[j] = predictLabels(trainInputsSquaredPost, trainOutputsNew)\n",
    "    \n",
    "print(\"Average accuracy NonNegativePre:\", np.mean(accuracy_NonNegativePre))\n",
    "print(\"Average accuracy NonNegativePost:\", np.mean(accuracy_NonNegativePost))\n",
    "print(\"Average accuracy ZeroOnePre:\", np.mean(accuracy_ZeroOnePre))\n",
    "print(\"Average accuracy ZeroOnePost:\", np.mean(accuracy_ZeroOnePost))\n",
    "print(\"Average accuracy SquaredPre:\", np.mean(accuracy_SquaredPre))\n",
    "print(\"Average accuracy SquaredPost:\", np.mean(accuracy_SquaredPost))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3255768  0.17684966 0.10279152 0.08734447 0.05666658]\n",
      "[0.32259331 0.18185452 0.09971127 0.08574962 0.05633363]\n",
      "[0.32957766 0.11031341 0.0962252  0.08014898 0.05482995]\n",
      "[0.34802061 0.11580156 0.0901371  0.07660845 0.05427013]\n",
      "[0.26853369 0.19097212 0.10633549 0.06034419 0.03827272]\n",
      "[0.30407787 0.15645354 0.12452489 0.06535366 0.03582739]\n"
     ]
    }
   ],
   "source": [
    "# Perform preprocessing: PCA\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Try: all data in one vector\n",
    "trainInputsList = [trainInputsNonNegativePre, trainInputsNonNegativePost, trainInputsZeroOnePre, trainInputsZeroOnePost, trainInputsSquaredPre, trainInputsSquaredPost]\n",
    "\n",
    "for PCAInputs in trainInputsList:\n",
    "    Outputs = np.reshape(trainOutputsNew, (270,1))\n",
    "    #print(Outputs)\n",
    "    allTrainInputs = np.concatenate([PCAInputs,Outputs],axis=1)\n",
    "    \n",
    "    datasetPCA = pd.DataFrame(allTrainInputs)\n",
    "    \n",
    "    pca = PCA(n_components=5)\n",
    "    pca.fit(datasetPCA)\n",
    "    principalComponents = pca.fit_transform(datasetPCA)\n",
    "\n",
    "    print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(allTrainInputs)\n",
    "\n",
    "# Prints PCA plot (Does only work with a PCA with 2 components)\n",
    "# Code based on https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
    "principalComponents = pca.fit_transform(allTrainInputs)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "finalDf = pd.concat([principalDf, pd.DataFrame(allTrainInputsLabeled)], axis = 1)\n",
    "# print(finalDf)\n",
    "\n",
    "fig = plt.figure(figsize = (12,12))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "# Choose the speakers that you want to visualize in the plot\n",
    "targets = [1, 3, 4]\n",
    "colors = 'r', 'g', 'b'\n",
    "# Uncomment if you want to visualize all speakers\n",
    "#targets = [1,2,3,4,5,6,7,8,9]\n",
    "#colors = ['r', 'g', 'b', 'k', 'c', 'm', 'y', 'tab:orange', 'tab:brown']\n",
    "\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf[0] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with different Data structure\n",
    "from sklearn import svm\n",
    "\n",
    "# Implementation Support Vector Machine\n",
    "def SVM_alt(inputs_train, outputs_train, inputs_test):    \n",
    "    # Create a classifier \n",
    "    classifier = svm.SVC(kernel='linear')    \n",
    "    outputs_train = outputs_train.astype('int')\n",
    "    classifier.fit(inputs_train, outputs_train)\n",
    "    \n",
    "    # Predict the test data\n",
    "    labels_prediction = classifier.predict(inputs_test)\n",
    "\n",
    "    return labels_prediction\n",
    "\n",
    "def predictLabels_alt(inputs_train, inputs_test, outputs_train, outputs_test):\n",
    "    #inputs_train, inputs_test, outputs_train, outputs_test = splitData(trainInputs, trainOutputs)\n",
    "\n",
    "    # Predict the test labels\n",
    "    prediction = SVM_alt(inputs_train, outputs_train, inputs_test)\n",
    "\n",
    "    # Print results\n",
    "    wrong = 0\n",
    "    length = len(prediction)\n",
    "    for i in range(length):\n",
    "        #print(prediction[i], np.ravel(outputs_test)[i])\n",
    "        if(prediction[i] != np.ravel(outputs_test)[i]):\n",
    "            wrong = wrong + 1\n",
    "\n",
    "    return ((length - wrong) / length) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Reduction with Self-organising maps (SOM)\n",
    "# The results are pretty depressing\n",
    "# pip3 install susi\n",
    "import sys\n",
    "sys.path.append('/Users/lauridsstockert/opt/anaconda3/lib/python3.7/site-packages')\n",
    "\n",
    "import susi\n",
    "# Same Problem as with UMAP. Will work for you without this line I think.\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {\n",
    "    \"n_rows\": [5, 10, 20],\n",
    "    \"n_columns\": [5, 20, 40],\n",
    "    \"learning_rate_start\": [0.5, 0.7, 0.9],\n",
    "    \"learning_rate_end\": [0.1, 0.05, 0.005],\n",
    "}\n",
    "som = susi.SOMClustering()\n",
    "#clf = RandomizedSearchCV(som, param_grid, random_state=1)\n",
    "#clf.fit(inputs_train)\n",
    "#print(clf.best_params_)\n",
    "inputs_train_som = som.fit_transform(inputs_train)\n",
    "inputs_test_som = som.fit_transform(inputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    accuracy_padded_after[i] = predictLabels_alt(inputs_train_som, inputs_test_som, outputs_train, outputs_test)\n",
    "print(\"Av. Accuracy (padding after)\", np.mean(accuracy_padded_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Reduction with UMAP\n",
    "# The results are equally depressing\n",
    "# pip3 install umap-learn\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "# Installing didn't work on my machine, so I provided tha path manually\n",
    "sys.path.append('/Users/lauridsstockert/opt/anaconda3/lib/python3.7/site-packages')\n",
    "\n",
    "import umap\n",
    "\n",
    "sns.set(style='white', context='poster', rc={'figure.figsize':(14,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def umapFun(input_data, n_neighbors, n_components, min_dist):\n",
    "    reducer = umap.UMAP(n_neighbors=n_neighbors, n_components = n_components, min_dist = min_dist)\n",
    "    embedding = reducer.fit_transform(input_data)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trying Data Reduction with UMAP\n",
    "# The results are depressing\n",
    "accuracy_padded_after = np.zeros(100)\n",
    "#accuracy_padded_before = np.zeros(100)\n",
    "cnt = 1\n",
    "\n",
    "for n in (2, 5, 10, 20, 50, 100, 200):\n",
    "    for d in (0.8, 0.99):\n",
    "        for c in (2, 7):\n",
    "            accuracy_padded_after = np.zeros(100)\n",
    "            inputs_train_umap = umapFun(inputs_train, n, c, d)\n",
    "            inputs_test_umap = umapFun(inputs_test, n, c, d)\n",
    "            for i in range(100):\n",
    "                accuracy_padded_after[i] = predictLabels_alt(inputs_train_umap, inputs_test_umap, outputs_train , outputs_test)\n",
    "            print(\"cnt:\", cnt)\n",
    "            print(\"Av. Accuracy (padding after)\", np.mean(accuracy_padded_after))\n",
    "            cnt = cnt + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
