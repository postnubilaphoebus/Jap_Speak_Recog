{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Project: Japanese Vowel speaker classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data into time series arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing data sets\n",
    "trainData = np.loadtxt(\"ae.train\")\n",
    "testData = np.loadtxt(\"ae.test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview: \n",
    "* Training: 270 (30 utterances by 9 speakers. See file 'size_ae.train'.) \n",
    "* Testing: 370 (24-88 utterances by the same 9 speakers in different opportunities. See file 'size_ae.test'.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtaining 270 training time series arrays\n",
    "# arrays are (N x 12); where N is length of time series recording and 12 is number of dimensions (ie channels)\n",
    "trainInputs = np.empty((270,1), dtype=object)\n",
    "readindex = 0\n",
    "\n",
    "for i in range(1,271):\n",
    "    readindex = readindex + 1  \n",
    "    l = 0\n",
    "    while trainData[readindex-1, 1] != 1:\n",
    "        l = l + 1 \n",
    "        readindex = readindex + 1\n",
    "    trainInputs[i-1,0] = trainData[readindex-l-1:readindex-1,:]\n",
    "\n",
    "\n",
    "# obtaining 370 test time series arrays \n",
    "# arrays are (N x 12); where N is length of time series recording and 12 is number of dimensions (ie channels)\n",
    "testInputs = np.empty((370,1), dtype=object)\n",
    "readindex = 0\n",
    "\n",
    "# The last 12 entries of each recording are 1s, indicating 12 channels\n",
    "# They are droppped when reading in the data\n",
    "for i in range(1,371):\n",
    "    readindex = readindex + 1\n",
    "    l = 0 \n",
    "    while testData[readindex-1, 1] != 1:\n",
    "        l = l+1 \n",
    "        readindex = readindex + 1\n",
    "    testInputs[i-1,0] = testData[readindex-l-1:readindex-1,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtaining 270 training outputs (speaker targets)\n",
    "# arrays are (N x 9); where N is length of time series recording and 9 is number of different speakers\n",
    "# the speaker is indicated with a '1'\n",
    "trainOutputs = np.empty((270,1), dtype=object)\n",
    "\n",
    "for i in range(1,271):\n",
    "    l = np.size(trainInputs[i-1,0],0)\n",
    "    teacher = np.zeros((l,9))\n",
    "    speakerIndex = np.ceil(i/30)\n",
    "    teacher[:,np.int(speakerIndex)-1] = 1 \n",
    "    trainOutputs[i-1,0] = teacher\n",
    "\n",
    "# obtaining 370 test outputs (speaker targets)\n",
    "# arrays are (N x 9); where N is length of time series recording and 9 is number of different speakers\n",
    "# the speaker is indicated with a '1'\n",
    "testOutputs = np.empty((370,1), dtype=object)\n",
    "speakerIndex = 1\n",
    "blockCounter = 0\n",
    "blockLengthes = [31, 35, 88, 44, 29, 24, 40, 50, 29]\n",
    "for i in range(1, 371):\n",
    "    blockCounter = blockCounter + 1 \n",
    "    if blockCounter == blockLengthes[speakerIndex-1] + 1:\n",
    "        speakerIndex = speakerIndex + 1\n",
    "        blockCounter = 1\n",
    "    l = np.size(testInputs[i-1,0], 0)\n",
    "    teacher = np.zeros((l,9))\n",
    "    teacher[:,np.int(speakerIndex)-1] = 1   \n",
    "    testOutputs[i-1, 0] = teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x257ca6bacf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prints histogram of timeseries length (exploratory analysis)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "histos = np.zeros(270)\n",
    "\n",
    "for i in range(270):\n",
    "    histos[i] = (len(trainInputs[i, 0]))\n",
    "\n",
    "#print(histos)\n",
    "plt.title('Counting timeseries length (total 270)')\n",
    "plt.xlabel('Timeseries length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(histos, bins = 20, ec='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add length of each recording as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "RecordingLength = histos\n",
    "for i in range(270):\n",
    "    RecordingLength[i] = RecordingLength[i] / 26\n",
    "#print(RecordingLength)\n",
    "\n",
    "for i in range(270):\n",
    "    lenArray = len(trainInputs[i][0])\n",
    "    rec = np.full(lenArray, RecordingLength[i])\n",
    "    newArray = np.column_stack((trainInputs[i][0][:], rec))\n",
    "    trainInputs[i][0] = newArray\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing: Subtract minimum value of channel from each value. Finish with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#according to the paper by Dwarampudi et al 2019(in whatsappchat), prepadding is preferred. \n",
    "#However we seem to get better results with postpadding. That's why both are kept for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First: Find minimum of all channels of all samples\n",
    "minimum = np.zeros(13)\n",
    "for sample in trainInputs:\n",
    "    for array in sample[0]:\n",
    "        channelnumber = 0\n",
    "        for number in array:\n",
    "            if number < minimum[channelnumber]:\n",
    "                minimum[channelnumber] = number\n",
    "            channelnumber = channelnumber + 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.783783 -1.852765 -0.745858 -0.957525 -0.691587 -0.83559  -0.616608\n",
      " -0.57128  -0.623201 -0.503843 -0.426728 -0.336968  0.      ]\n"
     ]
    }
   ],
   "source": [
    "print(minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Subtract minimum value from all values per channel\n",
    "trainInputsNonNegative = copy.deepcopy(trainInputs)\n",
    "samplenumber = 0\n",
    "for sample in trainInputsNonNegative:\n",
    "    arraynumber = 0\n",
    "    for array in sample[0]:\n",
    "        channelnumber = 0\n",
    "        for number in array:\n",
    "            trainInputsNonNegative[samplenumber][0][arraynumber][channelnumber] = number - minimum[channelnumber]\n",
    "            channelnumber = channelnumber + 1\n",
    "        arraynumber = arraynumber + 1\n",
    "    samplenumber = samplenumber + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pads the training inputs with zeroes to make all the timeseries of equal length\n",
    "size_max = 13 * 26\n",
    "trainInputsNonNegativePre = np.empty((270,size_max), dtype=object)\n",
    "trainInputsNonNegativePost = np.empty((270,size_max), dtype=object)\n",
    "\n",
    "idx = 0 \n",
    "for element in trainInputsNonNegative:\n",
    "    element = np.ndarray.flatten(element[0])\n",
    "    # Pads zeroes before    \n",
    "    elements = element\n",
    "    elements = np.pad(elements, (size_max - len(elements), 0), 'constant')\n",
    "    trainInputsNonNegativePre[idx] = elements\n",
    "    \n",
    "    # Pads zeroes after\n",
    "    # Pad element with zeroes until it reaches the shape of the largest timeseries (12 * 26 = 312)\n",
    "    shape = np.shape(element)\n",
    "    padded_array = np.zeros(size_max)\n",
    "    padded_array[:shape[0]] = element  \n",
    "    element = padded_array\n",
    "    # print(element)\n",
    "\n",
    "    trainInputsNonNegativePost[idx] = element\n",
    "    idx = idx + 1\n",
    "\n",
    "trainOutputsNew = np.empty((270,1), dtype=object)\n",
    "\n",
    "# Transforms the trainOutputs in classes 1-9\n",
    "idxx = 0\n",
    "for elements in trainOutputs:\n",
    "    for i in range(len(elements[0][0])):\n",
    "       if elements[0][0][i] == 1:\n",
    "           trainOutputsNew[idxx] = i + 1\n",
    "           idxx = idxx + 1\n",
    "        \n",
    "trainOutputsNew = np.ravel(trainOutputsNew)\n",
    "trainOutputsNew = trainOutputsNew.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing 2: Put numbers in range 0-1. Finish with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Additionally set numbers between 0/1\n",
    "#Find maximum per channel\n",
    "trainInputsZeroOne = copy.deepcopy(trainInputsNonNegative)\n",
    "maximum = np.zeros(13)\n",
    "for sample in trainInputs:\n",
    "    for array in sample[0]:\n",
    "        channelnumber = 0\n",
    "        for number in array:\n",
    "            if number > maximum[channelnumber]:\n",
    "                maximum[channelnumber] = number\n",
    "            channelnumber = channelnumber + 1\n",
    "\n",
    "#divide by maximum value per channel\n",
    "samplenumber = 0\n",
    "for sample in trainInputsZeroOne:\n",
    "    arraynumber = 0\n",
    "    for array in sample[0]:\n",
    "        channelnumber = 0\n",
    "        for number in array:\n",
    "            trainInputsZeroOne[samplenumber][0][arraynumber][channelnumber] = number / maximum[channelnumber]\n",
    "            channelnumber = channelnumber + 1\n",
    "        arraynumber = arraynumber + 1\n",
    "    samplenumber = samplenumber + 1\n",
    "\n",
    "#pad the samples\n",
    "size_max = 13 * 26\n",
    "trainInputsZeroOnePre = np.empty((270,size_max), dtype=object)\n",
    "trainInputsZeroOnePost = np.empty((270,size_max), dtype=object)\n",
    "\n",
    "idx = 0 \n",
    "for element in trainInputsZeroOne:\n",
    "    element = np.ndarray.flatten(element[0])\n",
    "    # Pads zeroes before    \n",
    "    elements = element\n",
    "    elements = np.pad(elements, (size_max - len(elements), 0), 'constant')\n",
    "    trainInputsZeroOnePre[idx] = elements\n",
    "    \n",
    "    # Pads zeroes after\n",
    "    # Pad element with zeroes until it reaches the shape of the largest timeseries (13 * 26 = 338)\n",
    "    shape = np.shape(element)\n",
    "    padded_array = np.zeros(size_max)\n",
    "    padded_array[:shape[0]] = element  \n",
    "    element = padded_array\n",
    "\n",
    "    trainInputsZeroOnePost[idx] = element\n",
    "    idx = idx + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing 3: Induce bias by squaring. Finish with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalize/Bias numbers by squaring\n",
    "trainInputsSquared = copy.deepcopy(trainInputsZeroOne)\n",
    "\n",
    "#divide by maximum value per channel\n",
    "samplenumber = 0\n",
    "for sample in trainInputsSquared:\n",
    "    arraynumber = 0\n",
    "    for array in sample[0]:\n",
    "        channelnumber = 0\n",
    "        for number in array:\n",
    "            trainInputsSquared[samplenumber][0][arraynumber][channelnumber] = number *number\n",
    "            channelnumber = channelnumber + 1\n",
    "        arraynumber = arraynumber + 1\n",
    "    samplenumber = samplenumber + 1\n",
    "\n",
    "#pad normalized further samples\n",
    "size_max = 13 * 26\n",
    "trainInputsSquaredPre = np.empty((270,size_max), dtype=object)\n",
    "trainInputsSquaredPost = np.empty((270,size_max), dtype=object)\n",
    "\n",
    "idx = 0 \n",
    "for element in trainInputsSquared:\n",
    "    element = np.ndarray.flatten(element[0])\n",
    "    # Pads zeroes before    \n",
    "    elements = element\n",
    "    elements = np.pad(elements, (size_max - len(elements), 0), 'constant')\n",
    "    trainInputsSquaredPre[idx] = elements\n",
    "    \n",
    "    # Pads zeroes after\n",
    "    # Pad element with zeroes until it reaches the shape of the largest timeseries (13 * 26 = 338)\n",
    "    shape = np.shape(element)\n",
    "    padded_array = np.zeros(size_max)\n",
    "    padded_array[:shape[0]] = element  \n",
    "    element = padded_array\n",
    "\n",
    "    trainInputsSquaredPost[idx] = element\n",
    "    idx = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length inputs_train: 216\n",
      "Length outputs_train: 216\n",
      "Length inputs_test: 270\n",
      "Length trainOutputsNew: 270\n"
     ]
    }
   ],
   "source": [
    "# Crossvalidation. Currently only splitting in train-test data. Ideally, we want a validation set as well (e.g. 80 - 10 - 10 or 60 - 20 - 20)\n",
    "# Function taken from my Intro to Data Science assignment 3 code\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def splitData(inputs, outputs):   \n",
    "    # To avoid overfitting, we divide the dataset into a part for training and a part for testing\n",
    "    # We split the dataset into 80% training data and 20% testing data\n",
    "    inputs_train, inputs_test, outputs_train, outputs_test = train_test_split(\n",
    "            inputs, outputs, test_size=0.20) \n",
    "    \n",
    "    return inputs_train, inputs_test, outputs_train, outputs_test\n",
    "\n",
    "inputs_train, inputs_test, outputs_train, outputs_test = splitData(trainInputsNonNegative, trainOutputsNew)\n",
    "\n",
    "print('Length inputs_train:', len(inputs_train))\n",
    "print('Length outputs_train:', len(outputs_train))\n",
    "print('Length inputs_test:', len(trainOutputsNew))\n",
    "print('Length trainOutputsNew:', len(trainOutputsNew))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leann\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\leann\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\leann\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\leann\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy NonNegativePre: 96.29629629629629\n",
      "Average accuracy NonNegativePost: 90.74074074074075\n",
      "Average accuracy ZeroOnePre: 92.5925925925926\n",
      "Average accuracy ZeroOnePost: 88.88888888888889\n",
      "Average accuracy SquaredPre: 92.5925925925926\n",
      "Average accuracy SquaredPost: 88.88888888888889\n",
      "hello?\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Implementation Support Vector Machine\n",
    "def SVM(inputs_train, outputs_train, inputs_test):    \n",
    "    # Create a classifier \n",
    "    classifier = svm.SVC(kernel='linear')    \n",
    "    outputs_train = outputs_train.astype('int')\n",
    "    classifier.fit(inputs_train, outputs_train)\n",
    "    \n",
    "    # Predict the test data\n",
    "    labels_prediction = classifier.predict(inputs_test)\n",
    "\n",
    "    return labels_prediction\n",
    "\n",
    "\n",
    "# Implementation Multilayer Perceptron\n",
    "def MLP(inputs_train, outputs_train, inputs_test):\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(30, 20, 20), \n",
    "                               max_iter=2000, activation = 'relu',solver='adam',random_state=1)\n",
    "    outputs_train = outputs_train.astype('int')\n",
    "    classifier.fit(inputs_train, outputs_train)\n",
    "    \n",
    "    # Predict the test data\n",
    "    labels_prediction = classifier.predict(inputs_test)\n",
    "\n",
    "    return labels_prediction\n",
    "\n",
    "def simpleLogisticRegression(inputs_train, outputs_train, inputs_test):\n",
    "    model = LogisticRegression(max_iter=500)\n",
    "    outputs_train = outputs_train.astype('int')\n",
    "\n",
    "    model.fit(inputs_train, outputs_train)\n",
    "\n",
    "    labels_prediction = model.predict(inputs_test)\n",
    "    #print(labels_prediction)\n",
    "    \n",
    "    return labels_prediction\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "\"\"\" Creates ensemble classifier with our best performing classifiers\"\"\"\n",
    "# Code based on code from assignment of IDS.\n",
    "def createEnsemble():\n",
    "    # Our best performing classifiers\n",
    "    classifier1 = svm.SVC(kernel='linear')  \n",
    "    # classifier2 = LogisticRegression(max_iter=500)\n",
    "    \n",
    "    classifier3 = MLPClassifier(hidden_layer_sizes=(30, 20, 20), \n",
    "                               max_iter=2000, activation = 'relu',solver='adam',random_state=1)\n",
    "    classifier4 = svm.SVC(kernel='poly')\n",
    "    \n",
    "    ensemble = VotingClassifier(estimators = [('SVM_linear', classifier1),  \n",
    "                                              ('mlp', classifier3), ('SVM_poly', classifier4), \n",
    "                                              ], voting = 'hard')\n",
    "    \n",
    "    return ensemble\n",
    "\n",
    "\"\"\" Returns prediction from ensemble classifier\"\"\"   \n",
    "def ensemble(inputs_train, outputs_train, inputs_test):\n",
    "    ensemble = createEnsemble()\n",
    "    ensemble.fit(inputs_train, outputs_train) \n",
    "    \n",
    "    # Predict the test data\n",
    "    labels_prediction = ensemble.predict(inputs_test)\n",
    "    \n",
    "    return labels_prediction\n",
    "\n",
    "\n",
    "def predictLabels(trainInputs, trainOutputs):\n",
    "    inputs_train, inputs_test, outputs_train, outputs_test = splitData(trainInputs, trainOutputs)\n",
    "\n",
    "    # Predict the test labels\n",
    "    prediction = ensemble(inputs_train, outputs_train, inputs_test)\n",
    "\n",
    "    # Print results\n",
    "    wrong = 0\n",
    "    length = len(prediction)\n",
    "    for i in range(length):\n",
    "        #print(prediction[i], np.ravel(outputs_test)[i])\n",
    "        if(prediction[i] != np.ravel(outputs_test)[i]):\n",
    "            wrong = wrong + 1\n",
    "\n",
    "    return ((length - wrong) / length) * 100\n",
    "\n",
    "print('Go')\n",
    "\n",
    "no_iterations = 1\n",
    "#Pre is for prepadded, Post for postpadded\n",
    "accuracy_NonNegativePre = np.zeros(no_iterations)\n",
    "accuracy_NonNegativePost = np.zeros(no_iterations)\n",
    "accuracy_ZeroOnePre = np.zeros(no_iterations)\n",
    "accuracy_ZeroOnePost = np.zeros(no_iterations)\n",
    "accuracy_SquaredPre = np.zeros(no_iterations)\n",
    "accuracy_SquaredPost = np.zeros(no_iterations)\n",
    "for j in range(no_iterations):\n",
    "    accuracy_NonNegativePre[j] = predictLabels(trainInputsNonNegativePre, trainOutputsNew)\n",
    "    accuracy_NonNegativePost[j] = predictLabels(trainInputsNonNegativePost, trainOutputsNew)\n",
    "    accuracy_ZeroOnePre[j] = predictLabels(trainInputsZeroOnePre, trainOutputsNew)\n",
    "    accuracy_ZeroOnePost[j] = predictLabels(trainInputsZeroOnePost, trainOutputsNew)\n",
    "    accuracy_SquaredPre[j] = predictLabels(trainInputsSquaredPre, trainOutputsNew)\n",
    "    accuracy_SquaredPost[j] = predictLabels(trainInputsSquaredPost, trainOutputsNew)\n",
    "    \n",
    "print(\"Average accuracy NonNegativePre:\", np.mean(accuracy_NonNegativePre))\n",
    "print(\"Average accuracy NonNegativePost:\", np.mean(accuracy_NonNegativePost))\n",
    "print(\"Average accuracy ZeroOnePre:\", np.mean(accuracy_ZeroOnePre))\n",
    "print(\"Average accuracy ZeroOnePost:\", np.mean(accuracy_ZeroOnePost))\n",
    "print(\"Average accuracy SquaredPre:\", np.mean(accuracy_SquaredPre))\n",
    "print(\"Average accuracy SquaredPost:\", np.mean(accuracy_SquaredPost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3255768  0.17684966 0.10279152 0.08734447 0.05666658]\n",
      "[0.32259331 0.18185452 0.09971127 0.08574962 0.05633363]\n",
      "[0.32957766 0.11031341 0.0962252  0.08014898 0.05482995]\n",
      "[0.34802061 0.11580156 0.0901371  0.07660845 0.05427013]\n",
      "[0.26853369 0.19097212 0.10633549 0.06034419 0.03827272]\n",
      "[0.30407787 0.15645354 0.12452489 0.06535366 0.03582739]\n"
     ]
    }
   ],
   "source": [
    "# Perform preprocessing: PCA\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Try: all data in one vector\n",
    "trainInputsList = [trainInputsNonNegativePre, trainInputsNonNegativePost, trainInputsZeroOnePre, trainInputsZeroOnePost, trainInputsSquaredPre, trainInputsSquaredPost]\n",
    "Outputs = np.reshape(trainOutputsNew, (270,1))\n",
    "for PCAInputs in trainInputsList:\n",
    "    #print(Outputs)\n",
    "    allTrainInputs = np.concatenate([PCAInputs,Outputs],axis=1)\n",
    "    \n",
    "    datasetPCA = pd.DataFrame(allTrainInputs)\n",
    "    \n",
    "    pca = PCA(n_components=5)\n",
    "    pca.fit(datasetPCA)\n",
    "    principalComponents = pca.fit_transform(datasetPCA)\n",
    "\n",
    "    print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variation per principal component: [0.37461664 0.1290972 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtgAAALTCAYAAAAsFHXGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x257dd5b2ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(trainInputsNonNegativePre)\n",
    "\n",
    "# Prints PCA plot (Does only work with a PCA with 2 components)\n",
    "# Code based on https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
    "principalComponents = pca.fit_transform(trainInputsNonNegativePre)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "finalDf = pd.concat([principalDf, pd.DataFrame(Outputs)], axis = 1)\n",
    "#print(finalDf)\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
    "\n",
    "fig = plt.figure(figsize = (12,12))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "# Choose the speakers that you want to visualize in the plot\n",
    "targets = [1, 3, 4]\n",
    "colors = 'r', 'g', 'b'\n",
    "# Uncomment if you want to visualize all speakers\n",
    "#targets = [1,2,3,4,5,6,7,8,9]\n",
    "#colors = ['r', 'g', 'b', 'k', 'c', 'm', 'y', 'tab:orange', 'tab:brown']\n",
    "\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf[0] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-1147beeee7bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/lauridsstockert/opt/anaconda3/lib/python3.7/site-packages'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0msusi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# Same Problem as with UMAP. Will work for you without this line I think.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\susi\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \"\"\"\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mSOMClassifier\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSOMClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mSOMClustering\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSOMClustering\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mSOMEstimator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSOMEstimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\susi\\SOMClassifier.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mSOMEstimator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSOMEstimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mSOMUtils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_estimation_input\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\susi\\SOMEstimator.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mSOMClustering\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSOMClustering\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'tqdm'"
     ]
    }
   ],
   "source": [
    "# Data Reduction with Self-organising maps (SOM)\n",
    "# The results are pretty depressing\n",
    "# pip3 install susi\n",
    "import sys\n",
    "sys.path.append('/Users/lauridsstockert/opt/anaconda3/lib/python3.7/site-packages')\n",
    "\n",
    "import susi\n",
    "# Same Problem as with UMAP. Will work for you without this line I think.\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {\n",
    "    \"n_rows\": [5, 10, 20],\n",
    "    \"n_columns\": [5, 20, 40],\n",
    "    \"learning_rate_start\": [0.5, 0.7, 0.9],\n",
    "    \"learning_rate_end\": [0.1, 0.05, 0.005],\n",
    "}\n",
    "som = susi.SOMClustering()\n",
    "#clf = RandomizedSearchCV(som, param_grid, random_state=1)\n",
    "#clf.fit(inputs_train)\n",
    "#print(clf.best_params_)\n",
    "inputs_train_som = som.fit_transform(inputs_train)\n",
    "inputs_test_som = som.fit_transform(inputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM with different Data structure\n",
    "from sklearn import svm\n",
    "\n",
    "# Implementation Support Vector Machine\n",
    "def SVM_alt(inputs_train, outputs_train, inputs_test):    \n",
    "    # Create a classifier \n",
    "    classifier = svm.SVC(kernel='linear')    \n",
    "    outputs_train = outputs_train.astype('int')\n",
    "    classifier.fit(inputs_train, outputs_train)\n",
    "    \n",
    "    # Predict the test data\n",
    "    labels_prediction = classifier.predict(inputs_test)\n",
    "\n",
    "    return labels_prediction\n",
    "\n",
    "def predictLabels_alt(inputs_train, inputs_test, outputs_train, outputs_test):\n",
    "    #inputs_train, inputs_test, outputs_train, outputs_test = splitData(trainInputs, trainOutputs)\n",
    "\n",
    "    # Predict the test labels\n",
    "    prediction = SVM_alt(inputs_train, outputs_train, inputs_test)\n",
    "\n",
    "    # Print results\n",
    "    wrong = 0\n",
    "    length = len(prediction)\n",
    "    for i in range(length):\n",
    "        #print(prediction[i], np.ravel(outputs_test)[i])\n",
    "        if(prediction[i] != np.ravel(outputs_test)[i]):\n",
    "            wrong = wrong + 1\n",
    "\n",
    "    return ((length - wrong) / length) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs_train_som' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-79e7b0f86192>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0maccuracy_padded_after\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictLabels_alt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_train_som\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs_test_som\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Av. Accuracy (padding after)\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_padded_after\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'inputs_train_som' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    accuracy_padded_after[i] = predictLabels_alt(inputs_train_som, inputs_test_som, outputs_train, outputs_test)\n",
    "print(\"Av. Accuracy (padding after)\", np.mean(accuracy_padded_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'umap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-d58ccc70ca87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/lauridsstockert/opt/anaconda3/lib/python3.7/site-packages'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mumap\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'white'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'poster'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'figure.figsize'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'umap'"
     ]
    }
   ],
   "source": [
    "# Data Reduction with UMAP\n",
    "# The results are equally depressing\n",
    "# pip3 install umap-learn\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "# Installing didn't work on my machine, so I provided tha path manually\n",
    "sys.path.append('/Users/lauridsstockert/opt/anaconda3/lib/python3.7/site-packages')\n",
    "\n",
    "import umap\n",
    "\n",
    "sns.set(style='white', context='poster', rc={'figure.figsize':(14,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def umapFun(input_data, n_neighbors, n_components, min_dist):\n",
    "    reducer = umap.UMAP(n_neighbors=n_neighbors, n_components = n_components, min_dist = min_dist)\n",
    "    embedding = reducer.fit_transform(input_data)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'umap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-57976e57c278>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0maccuracy_padded_after\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0minputs_train_umap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mumapFun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0minputs_test_umap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mumapFun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-c1e2f5132f48>\u001b[0m in \u001b[0;36mumapFun\u001b[1;34m(input_data, n_neighbors, n_components, min_dist)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mumapFun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_dist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mreducer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mumap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUMAP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_dist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreducer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'umap' is not defined"
     ]
    }
   ],
   "source": [
    "# Trying Data Reduction with UMAP\n",
    "# The results are depressing\n",
    "accuracy_padded_after = np.zeros(100)\n",
    "#accuracy_padded_before = np.zeros(100)\n",
    "cnt = 1\n",
    "\n",
    "for n in (2, 5, 10, 20, 50, 100, 200):\n",
    "    for d in (0.8, 0.99):\n",
    "        for c in (2, 7):\n",
    "            accuracy_padded_after = np.zeros(100)\n",
    "            inputs_train_umap = umapFun(inputs_train, n, c, d)\n",
    "            inputs_test_umap = umapFun(inputs_test, n, c, d)\n",
    "            for i in range(100):\n",
    "                accuracy_padded_after[i] = predictLabels_alt(inputs_train_umap, inputs_test_umap, outputs_train , outputs_test)\n",
    "            print(\"cnt:\", cnt)\n",
    "            print(\"Av. Accuracy (padding after)\", np.mean(accuracy_padded_after))\n",
    "            cnt = cnt + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECHO classifier implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# getting data in the right format\n",
    "\n",
    "# train data\n",
    "trainInputs_array = []\n",
    "trainOutputs_array = []\n",
    "\n",
    "for i in range(270):\n",
    "    ndim = np.shape(trainInputs[i][0])[0]\n",
    "    for j in range(ndim):\n",
    "        trainInputs_array.append(trainInputs[i][0][j])\n",
    "        trainOutputs_array.append(trainOutputs[i][0][j])\n",
    "\n",
    "# test data        \n",
    "testInputs_array = []\n",
    "testOutputs_array = []\n",
    "\n",
    "for i in range(370):\n",
    "    ndim = np.shape(testInputs[i][0])[0]\n",
    "    for j in range(ndim):\n",
    "        testInputs_array.append(testInputs[i][0][j])\n",
    "        testOutputs_array.append(testOutputs[i][0][j])\n",
    "    \n",
    "    \n",
    "# data arrays used for ESN; all the timesteps with its 12 channels (dim) in each recording put into a list\n",
    "trainInputs_array = np.asarray(trainInputs_array)     \n",
    "trainOutputs_array = np.asarray(trainOutputs_array)\n",
    "\n",
    "testInputs_array = np.asarray(testInputs_array)\n",
    "testOutputs_array = np.asarray(testOutputs_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (300,12) and (13,) not aligned: 12 (dim 1) != 13 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-3198c2410e31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m           random_state=42)\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtrain_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_error_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mesn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainInputs_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainOutputs_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mtest_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mesn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestInputs_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Master AI IS\\Machine Learning\\Github directory3\\Jap_Speak_Recog\\pyESN.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, inputs, outputs, inspect)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             states[n, :] = self._update(states[n - 1], inputs_scaled[n, :],\n\u001b[1;32m--> 181\u001b[1;33m                                         teachers_scaled[n - 1, :])\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;31m# learn the weights, i.e. find the linear combination of collected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Master AI IS\\Machine Learning\\Github directory3\\Jap_Speak_Recog\\pyESN.py\u001b[0m in \u001b[0;36m_update\u001b[1;34m(self, state, input_pattern, output_pattern)\u001b[0m\n\u001b[0;32m    118\u001b[0m             preactivation = (np.dot(self.W, state)\n\u001b[0;32m    119\u001b[0m                              \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_pattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m                              + np.dot(self.W_feedb, output_pattern))\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             preactivation = (np.dot(self.W, state)\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (300,12) and (13,) not aligned: 12 (dim 1) != 13 (dim 0)"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from pyESN import ESN\n",
    "\n",
    "esn = ESN(n_inputs = 12,\n",
    "          n_outputs = 9,\n",
    "          n_reservoir = 300,\n",
    "          spectral_radius = 1.5,\n",
    "          random_state=42)\n",
    "\n",
    "train_pred, mean_error_train = esn.fit(trainInputs_array, trainOutputs_array, inspect=True)\n",
    "test_pred = esn.predict(testInputs_array)\n",
    "\n",
    "print(\"Mean test error: \", np.mean((test_pred - testOutputs_array)**2))\n",
    "print(\"Mean training error:\", mean_error_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter optimization + cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "If no scoring is specified, the estimator passed should have a 'score' method. The estimator <pyESN.ESN object at 0x0000018E35214550> does not.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-49d58874a11d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mesn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mm_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mesn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainInputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainOutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \"\"\"\n\u001b[0;32m    398\u001b[0m     \u001b[1;31m# To ensure multimetric format is not supported\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    426\u001b[0m                 \u001b[1;34m\"If no scoring is specified, the estimator passed should \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m                 \u001b[1;34m\"have a 'score' method. The estimator %r does not.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m                 % estimator)\n\u001b[0m\u001b[0;32m    429\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         raise ValueError(\"For evaluating multiple scores, use \"\n",
      "\u001b[1;31mTypeError\u001b[0m: If no scoring is specified, the estimator passed should have a 'score' method. The estimator <pyESN.ESN object at 0x0000018E35214550> does not."
     ]
    }
   ],
   "source": [
    "esn = ESN(n_inputs = 12,\n",
    "          n_outputs = 9,\n",
    "          random_state=42)\n",
    "\n",
    "# parameter optimization\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=269, n_repeats=2, random_state=42)\n",
    "param_grid = {\"n_reservoir\": [200, 400, 600, 800, 1000]}\n",
    "\n",
    "clf = GridSearchCV(esn, param_grid)\n",
    "\n",
    "m_scores = cross_val_score(esn, trainInputs, trainOutputs, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
