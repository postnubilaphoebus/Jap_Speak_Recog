{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Project: Japanese Vowel speaker classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data into time series arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasfortuin/anaconda/lib/python3.6/site-packages/pandas/compat/_optional.py:124: UserWarning: Pandas requires version '1.2.1' or newer of 'bottleneck' (version '1.2.0' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing data sets\n",
    "trainData = np.loadtxt(\"ae.train\")\n",
    "testData = np.loadtxt(\"ae.test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview: \n",
    "* Training: 270 (30 utterances by 9 speakers. See file 'size_ae.train'.) \n",
    "* Testing: 370 (24-88 utterances by the same 9 speakers in different opportunities. See file 'size_ae.test'.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtaining 270 training time series arrays\n",
    "# arrays are (N x 12); where N is length of time series recording and 12 is number of dimensions (ie channels)\n",
    "trainInputs = np.empty((270,1), dtype=object)\n",
    "readindex = 0\n",
    "\n",
    "for i in range(1,271):\n",
    "    readindex = readindex + 1  \n",
    "    l = 0\n",
    "    while trainData[readindex-1, 1] != 1:\n",
    "        l = l + 1 \n",
    "        readindex = readindex + 1\n",
    "    trainInputs[i-1,0] = trainData[readindex-l-1:readindex-1,:]\n",
    "\n",
    "\n",
    "# obtaining 370 test time series arrays \n",
    "# arrays are (N x 12); where N is length of time series recording and 12 is number of dimensions (ie channels)\n",
    "testInputs = np.empty((370,1), dtype=object)\n",
    "readindex = 0\n",
    "\n",
    "# The last 12 entries of each recording are 1s, indicating 12 channels\n",
    "# They are droppped when reading in the data\n",
    "for i in range(1,371):\n",
    "    readindex = readindex + 1\n",
    "    l = 0 \n",
    "    while testData[readindex-1, 1] != 1:\n",
    "        l = l+1 \n",
    "        readindex = readindex + 1\n",
    "    testInputs[i-1,0] = testData[readindex-l-1:readindex-1,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtaining 270 training outputs (speaker targets)\n",
    "# arrays are (N x 9); where N is length of time series recording and 9 is number of different speakers\n",
    "# the speaker is indicated with a '1'\n",
    "trainOutputs = np.empty((270,1), dtype=object)\n",
    "\n",
    "for i in range(1,271):\n",
    "    l = np.size(trainInputs[i-1,0],0)\n",
    "    teacher = np.zeros((l,9))\n",
    "    speakerIndex = np.ceil(i/30)\n",
    "    teacher[:,np.int(speakerIndex)-1] = 1 \n",
    "    trainOutputs[i-1,0] = teacher\n",
    "\n",
    "# obtaining 370 test outputs (speaker targets)\n",
    "# arrays are (N x 9); where N is length of time series recording and 9 is number of different speakers\n",
    "# the speaker is indicated with a '1'\n",
    "testOutputs = np.empty((370,1), dtype=object)\n",
    "speakerIndex = 1\n",
    "blockCounter = 0\n",
    "blockLengthes = [31, 35, 88, 44, 29, 24, 40, 50, 29]\n",
    "for i in range(1, 371):\n",
    "    blockCounter = blockCounter + 1 \n",
    "    if blockCounter == blockLengthes[speakerIndex-1] + 1:\n",
    "        speakerIndex = speakerIndex + 1\n",
    "        blockCounter = 1\n",
    "    l = np.size(testInputs[i-1,0], 0)\n",
    "    teacher = np.zeros((l,9))\n",
    "    teacher[:,np.int(speakerIndex)-1] = 1   \n",
    "    testOutputs[i-1, 0] = teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\n/GZmJePEb2ZWMk78ZmYl8/9A+ZIbXyxtBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prints histogram of timeseries length (exploratory analysis)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "histos = np.zeros(270)\n",
    "\n",
    "for i in range(270):\n",
    "    histos[i] = (len(trainInputs[i, 0]))\n",
    "\n",
    "#print(histos)\n",
    "plt.title('Counting timeseries length (total 270)')\n",
    "plt.xlabel('Timeseries length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(histos, bins = 20, ec='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add length of each recording as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "RecordingLength = histos\n",
    "for i in range(270):\n",
    "    RecordingLength[i] = RecordingLength[i] / 26\n",
    "#print(RecordingLength)\n",
    "\n",
    "for i in range(270):\n",
    "    lenArray = len(trainInputs[i][0])\n",
    "    rec = np.full(lenArray, RecordingLength[i])\n",
    "    newArray = np.column_stack((trainInputs[i][0][:], rec))\n",
    "    trainInputs[i][0] = newArray\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing: Subtract minimum value of channel from each value. Finish with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#according to the paper by Dwarampudi et al 2019(in whatsappchat), prepadding is preferred. \n",
    "#However we seem to get better results with postpadding. That's why both are kept for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First: Find minimum of all channels of all samples\n",
    "minimum = np.zeros(13)\n",
    "for sample in trainInputs:\n",
    "    for array in sample[0]:\n",
    "        channelnumber = 0\n",
    "        for number in array:\n",
    "            if number < minimum[channelnumber]:\n",
    "                minimum[channelnumber] = number\n",
    "            channelnumber = channelnumber + 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.783783 -1.852765 -0.745858 -0.957525 -0.691587 -0.83559  -0.616608\n",
      " -0.57128  -0.623201 -0.503843 -0.426728 -0.336968  0.      ]\n"
     ]
    }
   ],
   "source": [
    "print(minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Subtract minimum value from all values per channel\n",
    "trainInputsNonNegative = copy.deepcopy(trainInputs)\n",
    "samplenumber = 0\n",
    "for sample in trainInputsNonNegative:\n",
    "    arraynumber = 0\n",
    "    for array in sample[0]:\n",
    "        channelnumber = 0\n",
    "        for number in array:\n",
    "            trainInputsNonNegative[samplenumber][0][arraynumber][channelnumber] = number - minimum[channelnumber]\n",
    "            channelnumber = channelnumber + 1\n",
    "        arraynumber = arraynumber + 1\n",
    "    samplenumber = samplenumber + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pads the training inputs with zeroes to make all the timeseries of equal length\n",
    "size_max = 13 * 26\n",
    "trainInputsNonNegativePre = np.empty((270,size_max), dtype=object)\n",
    "trainInputsNonNegativePost = np.empty((270,size_max), dtype=object)\n",
    "\n",
    "idx = 0 \n",
    "for element in trainInputsNonNegative:\n",
    "    element = np.ndarray.flatten(element[0])\n",
    "    # Pads zeroes before    \n",
    "    elements = element\n",
    "    elements = np.pad(elements, (size_max - len(elements), 0), 'constant')\n",
    "    trainInputsNonNegativePre[idx] = elements\n",
    "    \n",
    "    # Pads zeroes after\n",
    "    # Pad element with zeroes until it reaches the shape of the largest timeseries (12 * 26 = 312)\n",
    "    shape = np.shape(element)\n",
    "    padded_array = np.zeros(size_max)\n",
    "    padded_array[:shape[0]] = element  \n",
    "    element = padded_array\n",
    "    # print(element)\n",
    "\n",
    "    trainInputsNonNegativePost[idx] = element\n",
    "    idx = idx + 1\n",
    "\n",
    "trainOutputsNew = np.empty((270,1), dtype=object)\n",
    "\n",
    "# Transforms the trainOutputs in classes 1-9\n",
    "idxx = 0\n",
    "for elements in trainOutputs:\n",
    "    for i in range(len(elements[0][0])):\n",
    "       if elements[0][0][i] == 1:\n",
    "           trainOutputsNew[idxx] = i + 1\n",
    "           idxx = idxx + 1\n",
    "        \n",
    "trainOutputsNew = np.ravel(trainOutputsNew)\n",
    "trainOutputsNew = trainOutputsNew.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing 2: Put numbers in range 0-1. Finish with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Additionally set numbers between 0/1\n",
    "#Find maximum per channel\n",
    "trainInputsZeroOne = copy.deepcopy(trainInputsNonNegative)\n",
    "maximum = np.zeros(13)\n",
    "for sample in trainInputs:\n",
    "    for array in sample[0]:\n",
    "        channelnumber = 0\n",
    "        for number in array:\n",
    "            if number > maximum[channelnumber]:\n",
    "                maximum[channelnumber] = number\n",
    "            channelnumber = channelnumber + 1\n",
    "\n",
    "#divide by maximum value per channel\n",
    "samplenumber = 0\n",
    "for sample in trainInputsZeroOne:\n",
    "    arraynumber = 0\n",
    "    for array in sample[0]:\n",
    "        channelnumber = 0\n",
    "        for number in array:\n",
    "            trainInputsZeroOne[samplenumber][0][arraynumber][channelnumber] = number / maximum[channelnumber]\n",
    "            channelnumber = channelnumber + 1\n",
    "        arraynumber = arraynumber + 1\n",
    "    samplenumber = samplenumber + 1\n",
    "\n",
    "#pad the samples\n",
    "size_max = 13 * 26\n",
    "trainInputsZeroOnePre = np.empty((270,size_max), dtype=object)\n",
    "trainInputsZeroOnePost = np.empty((270,size_max), dtype=object)\n",
    "\n",
    "idx = 0 \n",
    "for element in trainInputsZeroOne:\n",
    "    element = np.ndarray.flatten(element[0])\n",
    "    # Pads zeroes before    \n",
    "    elements = element\n",
    "    elements = np.pad(elements, (size_max - len(elements), 0), 'constant')\n",
    "    trainInputsZeroOnePre[idx] = elements\n",
    "    \n",
    "    # Pads zeroes after\n",
    "    # Pad element with zeroes until it reaches the shape of the largest timeseries (13 * 26 = 338)\n",
    "    shape = np.shape(element)\n",
    "    padded_array = np.zeros(size_max)\n",
    "    padded_array[:shape[0]] = element  \n",
    "    element = padded_array\n",
    "\n",
    "    trainInputsZeroOnePost[idx] = element\n",
    "    idx = idx + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing 3: Induce bias by squaring. Finish with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalize/Bias numbers by squaring\n",
    "trainInputsSquared = copy.deepcopy(trainInputsZeroOne)\n",
    "\n",
    "#divide by maximum value per channel\n",
    "samplenumber = 0\n",
    "for sample in trainInputsSquared:\n",
    "    arraynumber = 0\n",
    "    for array in sample[0]:\n",
    "        channelnumber = 0\n",
    "        for number in array:\n",
    "            trainInputsSquared[samplenumber][0][arraynumber][channelnumber] = number *number\n",
    "            channelnumber = channelnumber + 1\n",
    "        arraynumber = arraynumber + 1\n",
    "    samplenumber = samplenumber + 1\n",
    "\n",
    "#pad normalized further samples\n",
    "size_max = 13 * 26\n",
    "trainInputsSquaredPre = np.empty((270,size_max), dtype=object)\n",
    "trainInputsSquaredPost = np.empty((270,size_max), dtype=object)\n",
    "\n",
    "idx = 0 \n",
    "for element in trainInputsSquared:\n",
    "    element = np.ndarray.flatten(element[0])\n",
    "    # Pads zeroes before    \n",
    "    elements = element\n",
    "    elements = np.pad(elements, (size_max - len(elements), 0), 'constant')\n",
    "    trainInputsSquaredPre[idx] = elements\n",
    "    \n",
    "    # Pads zeroes after\n",
    "    # Pad element with zeroes until it reaches the shape of the largest timeseries (13 * 26 = 338)\n",
    "    shape = np.shape(element)\n",
    "    padded_array = np.zeros(size_max)\n",
    "    padded_array[:shape[0]] = element  \n",
    "    element = padded_array\n",
    "\n",
    "    trainInputsSquaredPost[idx] = element\n",
    "    idx = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length inputs_train: 216\n",
      "Length outputs_train: 216\n",
      "Length inputs_test: 270\n",
      "Length trainOutputsNew: 270\n"
     ]
    }
   ],
   "source": [
    "# Crossvalidation. Currently only splitting in train-test data. Ideally, we want a validation set as well (e.g. 80 - 10 - 10 or 60 - 20 - 20)\n",
    "# Function taken from my Intro to Data Science assignment 3 code\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def splitData(inputs, outputs):   \n",
    "    # To avoid overfitting, we divide the dataset into a part for training and a part for testing\n",
    "    # We split the dataset into 80% training data and 20% testing data\n",
    "    inputs_train, inputs_test, outputs_train, outputs_test = train_test_split(\n",
    "            inputs, outputs, test_size=0.20) \n",
    "    \n",
    "    return inputs_train, inputs_test, outputs_train, outputs_test\n",
    "\n",
    "inputs_train, inputs_test, outputs_train, outputs_test = splitData(trainInputsNonNegative, trainOutputsNew)\n",
    "\n",
    "print('Length inputs_train:', len(inputs_train))\n",
    "print('Length outputs_train:', len(outputs_train))\n",
    "print('Length inputs_test:', len(trainOutputsNew))\n",
    "print('Length trainOutputsNew:', len(trainOutputsNew))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy NonNegativePre: 93.03703703703704\n",
      "Average accuracy NonNegativePost: 93.57407407407408\n",
      "Average accuracy ZeroOnePre: 93.31481481481484\n",
      "Average accuracy ZeroOnePost: 92.11111111111113\n",
      "Average accuracy SquaredPre: 91.09259259259261\n",
      "Average accuracy SquaredPost: 88.18518518518518\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Implementation Support Vector Machine\n",
    "def SVM(inputs_train, outputs_train, inputs_test):    \n",
    "    # Create a classifier \n",
    "    classifier = svm.SVC(kernel='linear')    \n",
    "    outputs_train = outputs_train.astype('int')\n",
    "    classifier.fit(inputs_train, outputs_train)\n",
    "    \n",
    "    # Predict the test data\n",
    "    labels_prediction = classifier.predict(inputs_test)\n",
    "\n",
    "    return labels_prediction\n",
    "\n",
    "def predictLabels(trainInputs, trainOutputs):\n",
    "    inputs_train, inputs_test, outputs_train, outputs_test = splitData(trainInputs, trainOutputs)\n",
    "\n",
    "    # Predict the test labels\n",
    "    prediction = SVM(inputs_train, outputs_train, inputs_test)\n",
    "\n",
    "    # Print results\n",
    "    wrong = 0\n",
    "    length = len(prediction)\n",
    "    for i in range(length):\n",
    "        #print(prediction[i], np.ravel(outputs_test)[i])\n",
    "        if(prediction[i] != np.ravel(outputs_test)[i]):\n",
    "            wrong = wrong + 1\n",
    "\n",
    "    return ((length - wrong) / length) * 100\n",
    "\n",
    "#Pre is for prepadded, Post for postpadded\n",
    "accuracy_NonNegativePre = np.zeros(100)\n",
    "accuracy_NonNegativePost = np.zeros(100)\n",
    "accuracy_ZeroOnePre = np.zeros(100)\n",
    "accuracy_ZeroOnePost = np.zeros(100)\n",
    "accuracy_SquaredPre = np.zeros(100)\n",
    "accuracy_SquaredPost = np.zeros(100)\n",
    "for j in range(100):\n",
    "    accuracy_NonNegativePre[j] = predictLabels(trainInputsNonNegativePre, trainOutputsNew)\n",
    "    accuracy_NonNegativePost[j] = predictLabels(trainInputsNonNegativePost, trainOutputsNew)\n",
    "    accuracy_ZeroOnePre[j] = predictLabels(trainInputsZeroOnePre, trainOutputsNew)\n",
    "    accuracy_ZeroOnePost[j] = predictLabels(trainInputsZeroOnePost, trainOutputsNew)\n",
    "    accuracy_SquaredPre[j] = predictLabels(trainInputsSquaredPre, trainOutputsNew)\n",
    "    accuracy_SquaredPost[j] = predictLabels(trainInputsSquaredPost, trainOutputsNew)\n",
    "    \n",
    "print(\"Average accuracy NonNegativePre:\", np.mean(accuracy_NonNegativePre))\n",
    "print(\"Average accuracy NonNegativePost:\", np.mean(accuracy_NonNegativePost))\n",
    "print(\"Average accuracy ZeroOnePre:\", np.mean(accuracy_ZeroOnePre))\n",
    "print(\"Average accuracy ZeroOnePost:\", np.mean(accuracy_ZeroOnePost))\n",
    "print(\"Average accuracy SquaredPre:\", np.mean(accuracy_SquaredPre))\n",
    "print(\"Average accuracy SquaredPost:\", np.mean(accuracy_SquaredPost))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3134709  0.18242293 0.10265295 0.08975472 0.05820799]\n",
      "[0.31048394 0.18774477 0.09947768 0.08807656 0.05777802]\n",
      "[0.32300499 0.11069784 0.09745102 0.08149895 0.05542144]\n",
      "[0.34225362 0.11581756 0.09160854 0.07772943 0.05482484]\n",
      "[0.26802846 0.19127227 0.10606008 0.06030352 0.03833379]\n",
      "[0.30359349 0.15662963 0.12439997 0.06539954 0.03590875]\n"
     ]
    }
   ],
   "source": [
    "# Perform preprocessing: PCA\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Try: all data in one vector\n",
    "trainInputsList = [trainInputsNonNegativePre, trainInputsNonNegativePost, trainInputsZeroOnePre, trainInputsZeroOnePost, trainInputsSquaredPre, trainInputsSquaredPost]\n",
    "Outputs = np.reshape(trainOutputsNew, (270,1))\n",
    "for PCAInputs in trainInputsList:\n",
    "    #print(Outputs)\n",
    "    allTrainInputs = np.concatenate([PCAInputs,Outputs],axis=1)\n",
    "    \n",
    "    datasetPCA = pd.DataFrame(allTrainInputs)\n",
    "    \n",
    "    pca = PCA(n_components=5)\n",
    "    pca.fit(datasetPCA)\n",
    "    principalComponents = pca.fit_transform(datasetPCA)\n",
    "\n",
    "    print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variation per principal component: [0.35991134 0.13078655]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasfortuin/anaconda/lib/python3.6/site-packages/pandas/compat/_optional.py:124: UserWarning: Pandas requires version '2.6.2' or newer of 'numexpr' (version '2.6.1' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAALTCAYAAAA2KJVIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nAABADARqAAAAIIb/HxcNs8NWo0M7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(trainInputsNonNegativePre)\n",
    "\n",
    "# Prints PCA plot (Does only work with a PCA with 2 components)\n",
    "# Code based on https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
    "principalComponents = pca.fit_transform(trainInputsNonNegativePre)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "finalDf = pd.concat([principalDf, pd.DataFrame(Outputs)], axis = 1)\n",
    "#print(finalDf)\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
    "\n",
    "fig = plt.figure(figsize = (12,12))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "# Choose the speakers that you want to visualize in the plot\n",
    "targets = [1, 3, 4]\n",
    "colors = 'r', 'g', 'b'\n",
    "# Uncomment if you want to visualize all speakers\n",
    "#targets = [1,2,3,4,5,6,7,8,9]\n",
    "#colors = ['r', 'g', 'b', 'k', 'c', 'm', 'y', 'tab:orange', 'tab:brown']\n",
    "\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf[0] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM with different Data structure\n",
    "from sklearn import svm\n",
    "\n",
    "# Implementation Support Vector Machine\n",
    "def SVM_alt(inputs_train, outputs_train, inputs_test):    \n",
    "    # Create a classifier \n",
    "    classifier = svm.SVC(kernel='linear')    \n",
    "    outputs_train = outputs_train.astype('int')\n",
    "    classifier.fit(inputs_train, outputs_train)\n",
    "    \n",
    "    # Predict the test data\n",
    "    labels_prediction = classifier.predict(inputs_test)\n",
    "\n",
    "    return labels_prediction\n",
    "\n",
    "def predictLabels_alt(inputs_train, inputs_test, outputs_train, outputs_test):\n",
    "    #inputs_train, inputs_test, outputs_train, outputs_test = splitData(trainInputs, trainOutputs)\n",
    "\n",
    "    # Predict the test labels\n",
    "    prediction = SVM_alt(inputs_train, outputs_train, inputs_test)\n",
    "\n",
    "    # Print results\n",
    "    wrong = 0\n",
    "    length = len(prediction)\n",
    "    for i in range(length):\n",
    "        #print(prediction[i], np.ravel(outputs_test)[i])\n",
    "        if(prediction[i] != np.ravel(outputs_test)[i]):\n",
    "            wrong = wrong + 1\n",
    "\n",
    "    return ((length - wrong) / length) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'susi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1147beeee7bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/lauridsstockert/opt/anaconda3/lib/python3.7/site-packages'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msusi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# Same Problem as with UMAP. Will work for you without this line I think.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'susi'"
     ]
    }
   ],
   "source": [
    "# Data Reduction with Self-organising maps (SOM)\n",
    "# The results are pretty depressing\n",
    "# pip3 install susi\n",
    "import sys\n",
    "sys.path.append('/Users/lauridsstockert/opt/anaconda3/lib/python3.7/site-packages')\n",
    "\n",
    "import susi\n",
    "# Same Problem as with UMAP. Will work for you without this line I think.\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {\n",
    "    \"n_rows\": [5, 10, 20],\n",
    "    \"n_columns\": [5, 20, 40],\n",
    "    \"learning_rate_start\": [0.5, 0.7, 0.9],\n",
    "    \"learning_rate_end\": [0.1, 0.05, 0.005],\n",
    "}\n",
    "som = susi.SOMClustering()\n",
    "#clf = RandomizedSearchCV(som, param_grid, random_state=1)\n",
    "#clf.fit(inputs_train)\n",
    "#print(clf.best_params_)\n",
    "inputs_train_som = som.fit_transform(inputs_train)\n",
    "inputs_test_som = som.fit_transform(inputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    accuracy_padded_after[i] = predictLabels_alt(inputs_train_som, inputs_test_som, outputs_train, outputs_test)\n",
    "print(\"Av. Accuracy (padding after)\", np.mean(accuracy_padded_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data Reduction with UMAP\n",
    "# The results are equally depressing\n",
    "# pip3 install umap-learn\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "# Installing didn't work on my machine, so I provided tha path manually\n",
    "sys.path.append('/Users/lauridsstockert/opt/anaconda3/lib/python3.7/site-packages')\n",
    "\n",
    "import umap\n",
    "\n",
    "sns.set(style='white', context='poster', rc={'figure.figsize':(14,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def umapFun(input_data, n_neighbors, n_components, min_dist):\n",
    "    reducer = umap.UMAP(n_neighbors=n_neighbors, n_components = n_components, min_dist = min_dist)\n",
    "    embedding = reducer.fit_transform(input_data)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trying Data Reduction with UMAP\n",
    "# The results are depressing\n",
    "accuracy_padded_after = np.zeros(100)\n",
    "#accuracy_padded_before = np.zeros(100)\n",
    "cnt = 1\n",
    "\n",
    "for n in (2, 5, 10, 20, 50, 100, 200):\n",
    "    for d in (0.8, 0.99):\n",
    "        for c in (2, 7):\n",
    "            accuracy_padded_after = np.zeros(100)\n",
    "            inputs_train_umap = umapFun(inputs_train, n, c, d)\n",
    "            inputs_test_umap = umapFun(inputs_test, n, c, d)\n",
    "            for i in range(100):\n",
    "                accuracy_padded_after[i] = predictLabels_alt(inputs_train_umap, inputs_test_umap, outputs_train , outputs_test)\n",
    "            print(\"cnt:\", cnt)\n",
    "            print(\"Av. Accuracy (padding after)\", np.mean(accuracy_padded_after))\n",
    "            cnt = cnt + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECHO classifier implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# getting data in the right format\n",
    "\n",
    "\n",
    "# train data\n",
    "trainInputs_array = []\n",
    "trainOutputs_array = []\n",
    "\n",
    "for i in range(270):\n",
    "    ndim = np.shape(trainInputs[i][0])[0]\n",
    "    for j in range(ndim):\n",
    "        trainInputs_array.append(trainInputs[i][0][j])\n",
    "        trainOutputs_array.append(trainOutputs[i][0][j])\n",
    "\n",
    "# test data        \n",
    "testInputs_array = []\n",
    "testOutputs_array = []\n",
    "\n",
    "for i in range(370):\n",
    "    ndim = np.shape(testInputs[i][0])[0]\n",
    "    for j in range(ndim):\n",
    "        testInputs_array.append(testInputs[i][0][j])\n",
    "        testOutputs_array.append(testOutputs[i][0][j])\n",
    "    \n",
    "    \n",
    "# data arrays used for ESN; all the timesteps with its 12 channels (dim) in each recording put into a list\n",
    "trainInputs_array = np.asarray(trainInputs_array)     \n",
    "trainOutputs_array = np.asarray(trainOutputs_array)\n",
    "\n",
    "testInputs_array = np.asarray(testInputs_array)\n",
    "testOutputs_array = np.asarray(testOutputs_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test error:  0.11331524472974415\n",
      "Mean training error: 0.028680546892281\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from pyESN import ESN\n",
    "\n",
    "esn = ESN(n_inputs = 12,\n",
    "          n_outputs = 9,\n",
    "          n_reservoir = 300,\n",
    "          spectral_radius = 1.5,\n",
    "          random_state=42)\n",
    "\n",
    "train_pred, mean_error_train = esn.fit(trainInputs_array, trainOutputs_array, inspect=True)\n",
    "test_pred = esn.predict(testInputs_array)\n",
    "\n",
    "print(\"Mean test error: \", np.mean((test_pred - testOutputs_array)**2))\n",
    "print(\"Mean training error:\", mean_error_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter optimization + cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "If no scoring is specified, the estimator passed should have a 'score' method. The estimator <pyESN.ESN object at 0x7fc2542944a8> does not.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-49d58874a11d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mesn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mm_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mesn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainInputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainOutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/thomasfortuin/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomasfortuin/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \"\"\"\n\u001b[1;32m    398\u001b[0m     \u001b[0;31m# To ensure multimetric format is not supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n",
      "\u001b[0;32m/Users/thomasfortuin/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomasfortuin/anaconda/lib/python3.6/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0;34m\"If no scoring is specified, the estimator passed should \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m                 \u001b[0;34m\"have a 'score' method. The estimator %r does not.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 % estimator)\n\u001b[0m\u001b[1;32m    429\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         raise ValueError(\"For evaluating multiple scores, use \"\n",
      "\u001b[0;31mTypeError\u001b[0m: If no scoring is specified, the estimator passed should have a 'score' method. The estimator <pyESN.ESN object at 0x7fc2542944a8> does not."
     ]
    }
   ],
   "source": [
    "esn = ESN(n_inputs = 12,\n",
    "          n_outputs = 9,\n",
    "          random_state=42)\n",
    "\n",
    "# parameter optimization\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=269, n_repeats=2, random_state=42)\n",
    "param_grid = {\"n_reservoir\": [200, 400, 600, 800, 1000]}\n",
    "\n",
    "clf = GridSearchCV(esn, param_grid)\n",
    "\n",
    "m_scores = cross_val_score(esn, trainInputs, trainOutputs, cv=cv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
