{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Project: Japanese Vowel speaker classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data into time series arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data sets\n",
    "trainData = np.loadtxt(\"ae.train\")\n",
    "testData = np.loadtxt(\"ae.test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview: \n",
    "* Training: 270 (30 utterances by 9 speakers. See file 'size_ae.train'.) \n",
    "* Testing: 370 (24-88 utterances by the same 9 speakers in different opportunities. See file 'size_ae.test'.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining 270 training time series arrays\n",
    "# arrays are (N x 12); where N is length of time series recording and 12 is number of dimensions (ie channels)\n",
    "trainInputs = np.empty((270,1), dtype=object)\n",
    "readindex = 0\n",
    "\n",
    "for i in range(1,271):\n",
    "    readindex = readindex + 1  \n",
    "    l = 0\n",
    "    while trainData[readindex-1, 1] != 1:\n",
    "        l = l + 1 \n",
    "        readindex = readindex + 1\n",
    "    trainInputs[i-1,0] = trainData[readindex-l-1:readindex-1,:]\n",
    "\n",
    "\n",
    "# obtaining 370 test time series arrays \n",
    "# arrays are (N x 12); where N is length of time series recording and 12 is number of dimensions (ie channels)\n",
    "testInputs = np.empty((370,1), dtype=object)\n",
    "readindex = 0\n",
    "\n",
    "# The last 12 entries of each recording are 1s, indicating 12 channels\n",
    "# They are droppped when reading in the data\n",
    "for i in range(1,371):\n",
    "    readindex = readindex + 1\n",
    "    l = 0 \n",
    "    while testData[readindex-1, 1] != 1:\n",
    "        l = l+1 \n",
    "        readindex = readindex + 1\n",
    "    testInputs[i-1,0] = testData[readindex-l-1:readindex-1,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining 270 training outputs (speaker targets)\n",
    "# arrays are (N x 9); where N is length of time series recording and 9 is number of different speakers\n",
    "# the speaker is indicated with a '1'\n",
    "trainOutputs = np.empty((270,1), dtype=object)\n",
    "\n",
    "for i in range(1,271):\n",
    "    l = np.size(trainInputs[i-1,0],0)\n",
    "    teacher = np.zeros((l,9))\n",
    "    speakerIndex = np.ceil(i/30)\n",
    "    teacher[:,np.int(speakerIndex)-1] = 1 \n",
    "    trainOutputs[i-1,0] = teacher\n",
    "\n",
    "# obtaining 370 test outputs (speaker targets)\n",
    "# arrays are (N x 9); where N is length of time series recording and 9 is number of different speakers\n",
    "# the speaker is indicated with a '1'\n",
    "testOutputs = np.empty((370,1), dtype=object)\n",
    "speakerIndex = 1\n",
    "blockCounter = 0\n",
    "blockLengthes = [31, 35, 88, 44, 29, 24, 40, 50, 29]\n",
    "for i in range(1, 371):\n",
    "    blockCounter = blockCounter + 1 \n",
    "    if blockCounter == blockLengthes[speakerIndex-1] + 1:\n",
    "        speakerIndex = speakerIndex + 1\n",
    "        blockCounter = 1\n",
    "    l = np.size(testInputs[i-1,0], 0)\n",
    "    teacher = np.zeros((l,9))\n",
    "    teacher[:,np.int(speakerIndex)-1] = 1   \n",
    "    testOutputs[i-1, 0] = teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms the trainOutputs & testOutputs in classes 1-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms the trainOutputs in classes 1-9\n",
    "trainOutputsNew = np.empty((270,1), dtype=object)\n",
    "idxx = 0\n",
    "for elements in trainOutputs:\n",
    "    for i in range(len(elements[0][0])):\n",
    "       if elements[0][0][i] == 1:\n",
    "           trainOutputsNew[idxx] = i + 1\n",
    "           idxx = idxx + 1\n",
    "        \n",
    "trainOutputsNew = np.ravel(trainOutputsNew)\n",
    "trainOutputsNew = trainOutputsNew.astype('int')\n",
    "\n",
    "# Transform the testOutputs in classes 1 - 9\n",
    "testOutputsNew = np.empty((370,1), dtype=object)\n",
    "idxx = 0\n",
    "for elements in testOutputs:\n",
    "    for i in range(len(elements[0][0])):\n",
    "       if elements[0][0][i] == 1:\n",
    "           testOutputsNew[idxx] = i + 1\n",
    "           idxx = idxx + 1\n",
    "        \n",
    "testOutputsNew = np.ravel(testOutputsNew)\n",
    "testOutputsNew = testOutputsNew.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prints histogram of timeseries length (exploratory analysis)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "histos = np.zeros(270)\n",
    "\n",
    "for i in range(270):\n",
    "    histos[i] = (len(trainInputs[i, 0]))\n",
    "\n",
    "#print(histos)\n",
    "plt.title('Counting timeseries length (total 270)')\n",
    "plt.xlabel('Timeseries length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(histos, bins = 20, ec='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add length of each recording as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add length of each recording for TRAINING data \n",
    "# ----------------------------------------------\n",
    "\n",
    "testLen = np.zeros(370)\n",
    "\n",
    "for i in range(270):\n",
    "    testLen[i] = len(trainInputs[i, 0]) / 26\n",
    "#print(RecordingLength)\n",
    "\n",
    "for i in range(270):\n",
    "    lenArray = len(trainInputs[i][0])\n",
    "    rec = np.full(lenArray, testLen[i])\n",
    "    newArray = np.column_stack((trainInputs[i][0][:], rec))\n",
    "    trainInputs[i][0] = newArray\n",
    "\n",
    "# Add length of each recording for TESTING data \n",
    "# ----------------------------------------------\n",
    "\n",
    "trainLen = np.zeros(370)\n",
    "# Maximum Length is 29\n",
    "for i in range(370):\n",
    "    trainLen[i] = len(testInputs[i, 0]) / 29\n",
    "\n",
    "for i in range(370):\n",
    "    lenArray = len(testInputs[i][0])\n",
    "    rec = np.full(lenArray, trainLen[i])\n",
    "    newArray = np.column_stack((testInputs[i][0][:], rec))\n",
    "    testInputs[i][0] = newArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing: Polynomial approximation (training and testing)Â¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Flattening & Reshaping the Test Data and Training Data. Both are padded using PREpadding. Padding is dropped in the polynomial approximation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ For TRAINING data ------------------------------\n",
    "\n",
    "size_train = 13 * 26\n",
    "PrePaddingTrain = np.empty((270,size_train), dtype=object)\n",
    "PostPaddingTrain = np.empty((270,size_train), dtype=object)\n",
    "\n",
    "idx = 0 \n",
    "for element in trainInputs:\n",
    "    # Flatten\n",
    "    element = np.ndarray.flatten(element[0])\n",
    "    # Pad zeros before  \n",
    "    elements = element\n",
    "    elements = np.pad(elements, (size_train - len(elements), 0), 'constant')\n",
    "    PrePaddingTrain[idx] = elements\n",
    "\n",
    "    # Pad zeros after\n",
    "    shape = np.shape(element)\n",
    "    padded_array = np.zeros(size_train)\n",
    "    padded_array[:shape[0]] = element  \n",
    "    element = padded_array\n",
    "    PostPaddingTrain[idx] = element\n",
    "    idx = idx + 1\n",
    "\n",
    "# Reshape ---------------------------------------------\n",
    "PrePaddingTrain = PrePaddingTrain.reshape(270, 26, 13)\n",
    "PostPaddingTrain = PostPaddingTrain.reshape(270, 26, 13)\n",
    "\n",
    "#------ For TESTING data ------------------------------\n",
    "\n",
    "size_test = 13 * 29\n",
    "PrePaddingTest = np.empty((370,size_test), dtype=object)\n",
    "PostPaddingTest = np.empty((370,size_test), dtype=object)\n",
    "\n",
    "idx = 0 \n",
    "for element in testInputs:\n",
    "    # Flatten\n",
    "    element = np.ndarray.flatten(element[0])\n",
    "    # Pad zeros before\n",
    "    # ----------------\n",
    "    elements = element\n",
    "    elements = np.pad(elements, (size_test - len(elements), 0), 'constant')\n",
    "    PrePaddingTest[idx] = elements\n",
    "\n",
    "    # Pad zeros after\n",
    "    # --------------\n",
    "    shape = np.shape(element)\n",
    "    padded_array = np.zeros(size_test)\n",
    "    padded_array[:shape[0]] = element  \n",
    "    element = padded_array\n",
    "    PostPaddingTest[idx] = element\n",
    "    idx = idx + 1\n",
    "\n",
    "# Reshape -------------------------------------------\n",
    "PrePaddingTest = PrePaddingTest.reshape(370, 29, 13)\n",
    "PostPaddingTest = PostPaddingTest.reshape(370, 29, 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Polynomial approximation (Resampling from the data using a polynomial approximation). Zeros are replaced with polynomial approximations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from scipy import interpolate\n",
    "\n",
    "# Function: polyApprox \n",
    "# ------------------------------------------------------------------\n",
    "# This function performs cubic polynomial approximation on a 3D input \n",
    "# that has an unequal amount of values per sample\n",
    "# ------------------------------------------------------------------\n",
    "# Parameters:\n",
    "# ---------\n",
    "# inputData: A 3D input array with uniform length across each sample\n",
    "# The last channel stores the length of a recording\n",
    "# ---------\n",
    "# sampleLen: Number of samples (eg 270)\n",
    "# ---------\n",
    "# recordingLen: The length of each recording. The input data is formatted s.t. each \n",
    "# sample has the maximum channel length and smaller recordings are padded with zeros (prepadding)\n",
    "# ---------\n",
    "# channelNum: The number of channels (eg 13)\n",
    "# ---------\n",
    "# finalLength: the length the input should be adjusted to. When this is smaller than recordingLength\n",
    "# we have under- and oversampling.\n",
    "# ---------\n",
    "\n",
    "def interpol(xValues, yValues, x):\n",
    "    cs = interpolate.splrep(xValues, yValues, k = 3)\n",
    "    return interpolate.splev(x, cs)\n",
    "\n",
    "def polyApprox(inputData, sampleLen, recordingLen, channelNum, finalLength):\n",
    "    PolyAugmentArray = np.zeros((sampleLen, finalLength, channelNum))\n",
    "\n",
    "    for i in range(sampleLen):\n",
    "        for j in range(channelNum):\n",
    "            if j == channelNum - 1:\n",
    "                for m in range(finalLength):\n",
    "                    PolyAugmentArray[i][m][channelNum - 1] = inputData[i][0][channelNum - 1]\n",
    "            else:\n",
    "                recordingLength = round(inputData[i][0][channelNum - 1] * recordingLen)\n",
    "                paddingLength = recordingLen - recordingLength\n",
    "                yValues = np.zeros(recordingLength)\n",
    "                xValues = np.zeros(recordingLength)\n",
    "                zValues = np.zeros(finalLength)\n",
    "\n",
    "                for k in range(recordingLength):\n",
    "                    xValues[k] = k + 1\n",
    "                    yValues[k] = inputData[i][k][j]\n",
    "                for l in range(finalLength):\n",
    "                    zValues[l] = 1 + l * ((recordingLength - 1)/(finalLength - 1))\n",
    "                #print(recordingLength)\n",
    "                #print(xValues)\n",
    "                #print(\"yValues: \")\n",
    "                #print(yValues)\n",
    "                #print(zValues)\n",
    "                predictedValues = interpol(xValues, yValues, zValues)\n",
    "                #print(\"predictValues: \")\n",
    "                #print(predictedValues)\n",
    "                for m in range(finalLength):\n",
    "                    PolyAugmentArray[i][m][j] = predictedValues[m]\n",
    "    return PolyAugmentArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets resampled to different lengths (from 10 up to 26)\n",
    "# Len = 26:\n",
    "train_Resampled_26 = polyApprox(PostPaddingTrain, 270, 26, 13, 26)\n",
    "test_Resampled_26 = polyApprox(PostPaddingTest, 370, 29, 13, 26)\n",
    "# Len = 25:\n",
    "train_Resampled_25 = polyApprox(PostPaddingTrain, 270, 26, 13, 25)\n",
    "test_Resampled_25 = polyApprox(PostPaddingTest, 370, 29, 13, 25)\n",
    "# Len = 24:\n",
    "train_Resampled_24 = polyApprox(PostPaddingTrain, 270, 26, 13, 24)\n",
    "test_Resampled_24 = polyApprox(PostPaddingTest, 370, 29, 13, 24)\n",
    "# Len = 23:\n",
    "train_Resampled_23 = polyApprox(PostPaddingTrain, 270, 26, 13, 23)\n",
    "test_Resampled_23 = polyApprox(PostPaddingTest, 370, 29, 13, 23)\n",
    "# Len = 22:\n",
    "train_Resampled_22 = polyApprox(PostPaddingTrain, 270, 26, 13, 22)\n",
    "test_Resampled_22 = polyApprox(PostPaddingTest, 370, 29, 13, 22)\n",
    "# Len = 21:\n",
    "train_Resampled_21 = polyApprox(PostPaddingTrain, 270, 26, 13, 21)\n",
    "test_Resampled_21 = polyApprox(PostPaddingTest, 370, 29, 13, 21)\n",
    "# Len = 20:\n",
    "train_Resampled_20 = polyApprox(PostPaddingTrain, 270, 26, 13, 20)\n",
    "test_Resampled_20 = polyApprox(PostPaddingTest, 370, 29, 13, 20)\n",
    "# Len = 19:\n",
    "train_Resampled_19 = polyApprox(PostPaddingTrain, 270, 26, 13, 19)\n",
    "test_Resampled_19 = polyApprox(PostPaddingTest, 370, 29, 13, 19)\n",
    "# Len = 18:\n",
    "train_Resampled_18 = polyApprox(PostPaddingTrain, 270, 26, 13, 18)\n",
    "test_Resampled_18 = polyApprox(PostPaddingTest, 370, 29, 13, 18)\n",
    "# Len = 17:\n",
    "train_Resampled_17 = polyApprox(PostPaddingTrain, 270, 26, 13, 17)\n",
    "test_Resampled_17 = polyApprox(PostPaddingTest, 370, 29, 13, 17)\n",
    "# Len = 16:\n",
    "train_Resampled_16 = polyApprox(PostPaddingTrain, 270, 26, 13, 16)\n",
    "test_Resampled_16 = polyApprox(PostPaddingTest, 370, 29, 13, 16)\n",
    "# Len = 15:\n",
    "train_Resampled_15 = polyApprox(PostPaddingTrain, 270, 26, 13, 15)\n",
    "test_Resampled_15 = polyApprox(PostPaddingTest, 370, 29, 13, 15)\n",
    "# Len = 14: \n",
    "train_Resampled_14 = polyApprox(PostPaddingTrain, 270, 26, 13, 14)\n",
    "test_Resampled_14 = polyApprox(PostPaddingTest, 370, 29, 13, 14)\n",
    "# Len = 13: \n",
    "train_Resampled_13 = polyApprox(PostPaddingTrain, 270, 26, 13, 13)\n",
    "test_Resampled_13 = polyApprox(PostPaddingTest, 370, 29, 13, 13)\n",
    "# Len = 12:\n",
    "train_Resampled_12 = polyApprox(PostPaddingTrain, 270, 26, 13, 12)\n",
    "test_Resampled_12 = polyApprox(PostPaddingTest, 370, 29, 13, 12)\n",
    "# Len = 11:\n",
    "train_Resampled_11 = polyApprox(PostPaddingTrain, 270, 26, 13, 11)\n",
    "test_Resampled_11 = polyApprox(PostPaddingTest, 370, 29, 13, 11)\n",
    "# Len = 10:\n",
    "train_Resampled_10 = polyApprox(PostPaddingTrain, 270, 26, 13, 10)\n",
    "test_Resampled_10 = polyApprox(PostPaddingTest, 370, 29, 13, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Normalisation (of training and testing (resampled)) between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function for normalising data that are not padded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal(inputData, sampleLen, recordingLen, channelNum):\n",
    "\n",
    "    # Find Minimum value and Maximum value of each channel for each sample\n",
    "    minResample = np.zeros(channelNum - 1)\n",
    "    maxResample = np.zeros(channelNum - 1)\n",
    "\n",
    "    inp = inputData\n",
    "\n",
    "    for i in range(sampleLen):\n",
    "        for j in range(channelNum - 1):\n",
    "            for k in range(recordingLen):\n",
    "                if inp[i][k][j] < minResample[j]:\n",
    "                    minResample[j] = inputData[i][k][j]\n",
    "                if inp[i][k][j] > maxResample[j]:\n",
    "                    maxResample[j] = inputData[i][k][j]\n",
    "\n",
    "    # Subtract minimum channel value from the respective sample values \n",
    "    # AND divide by maximum value\n",
    "\n",
    "    for i in range(sampleLen):\n",
    "        for j in range(channelNum - 1):\n",
    "            for k in range(recordingLen):\n",
    "                inp[i][k][j] = (inp[i][k][j] - minResample[j]) / (maxResample[j] - minResample[j])\n",
    "                \n",
    "    return inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function for normalising PADDED arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_padded_arrays(inputData, sampleLen, recordingLen, channelNum, paddingType):\n",
    "\n",
    "    # paddingType 0: prepadding\n",
    "    # paddingType 1: postpadding\n",
    "\n",
    "    # prepadding: start after padding length\n",
    "    # postpadding: stop before recordingLen - paddingLen\n",
    "\n",
    "    # Find Minimum value and Maximum value of each channel for each sample\n",
    "    minResample = np.zeros(channelNum - 1)\n",
    "    maxResample = np.zeros(channelNum - 1)\n",
    "\n",
    "    inp = inputData\n",
    "    unpaddedLen = 0\n",
    "    paddingLen = 0\n",
    "\n",
    "    for i in range(sampleLen):\n",
    "        if paddingType == 0:\n",
    "            unpaddedLen = round(inputData[i][25][channelNum - 1] * recordingLen)\n",
    "            paddingLen = recordingLen - unpaddedLen\n",
    "\n",
    "        if paddingType == 1:\n",
    "            unpaddedLen = round(inputData[i][0][channelNum - 1] * recordingLen)\n",
    "            paddingLen = 0\n",
    "\n",
    "        if paddingType > 1:\n",
    "            print(\"Input Error: paddingType must be either 0 or 1\")\n",
    "\n",
    "        for j in range(channelNum - 1):\n",
    "            for k in range(unpaddedLen):\n",
    "                if inp[i][k + paddingLen][j] < minResample[j]:\n",
    "                    minResample[j] = inputData[i][k + paddingLen][j]\n",
    "                if inp[i][k + paddingLen][j] > maxResample[j]:\n",
    "                    maxResample[j] = inputData[i][k + paddingLen][j]\n",
    "\n",
    "    # Subtract minimum channel value from the respective sample values \n",
    "    # AND divide by maximum value\n",
    "\n",
    "    for i in range(sampleLen):\n",
    "        for j in range(channelNum - 1):\n",
    "            for k in range(unpaddedLen):\n",
    "                inp[i][k + paddingLen][j] = (inp[i][k + paddingLen][j] - minResample[j]) / (maxResample[j] - minResample[j])\n",
    "                \n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PrePadding_3D = normalise_padded_arrays(PrePaddingTrain, 270, 26, 13, 0)\n",
    "PostPadding_3D = normalise_padded_arrays(PostPaddingTrain, 270, 26, 13, 1)\n",
    "\n",
    "PrePadding_2D = PrePadding_3D.reshape(270, 338)\n",
    "PostPadding_2D = PostPadding_3D.reshape(270, 338)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised datasets for different lengths\n",
    "\n",
    "# Len = 26:\n",
    "train_Resampled_26 = normal(train_Resampled_26, 270, 26, 13)\n",
    "test_Resampled_26 = normal(test_Resampled_26, 370, 26, 13)\n",
    "# Len = 25:\n",
    "train_Resampled_25 = normal(train_Resampled_25, 270, 25, 13)\n",
    "test_Resampled_25 = normal(test_Resampled_25, 370, 25, 13)\n",
    "# Len = 24:\n",
    "train_Resampled_24 = normal(train_Resampled_24, 270, 24, 13)\n",
    "test_Resampled_24 = normal(test_Resampled_24, 370, 24, 13)\n",
    "# Len = 23:\n",
    "train_Resampled_23 = normal(train_Resampled_23, 270, 23, 13)\n",
    "test_Resampled_23 = normal(test_Resampled_23, 370, 23, 13)\n",
    "# Len = 22:\n",
    "train_Resampled_22 = normal(train_Resampled_22, 270, 22, 13)\n",
    "test_Resampled_22 = normal(test_Resampled_22, 370, 22, 13)\n",
    "# Len = 21:\n",
    "train_Resampled_21 = normal(train_Resampled_21, 270, 21, 13)\n",
    "test_Resampled_21 = normal(test_Resampled_21, 370, 21, 13)\n",
    "# Len = 20:\n",
    "train_Resampled_20 = normal(train_Resampled_20, 270, 20, 13)\n",
    "test_Resampled_20 = normal(test_Resampled_20, 370, 20, 13)\n",
    "# Len = 19:\n",
    "train_Resampled_19 = normal(train_Resampled_19, 270, 19, 13)\n",
    "test_Resampled_19 = normal(test_Resampled_19, 370, 19, 13)\n",
    "# Len = 18:\n",
    "train_Resampled_18 = normal(train_Resampled_18, 270, 18, 13)\n",
    "test_Resampled_18 = normal(test_Resampled_18, 370, 18, 13)\n",
    "# Len = 17:\n",
    "train_Resampled_17 = normal(train_Resampled_17, 270, 17, 13)\n",
    "test_Resampled_17 = normal(test_Resampled_17, 370, 17, 13)\n",
    "# Len = 16:\n",
    "train_Resampled_16 = normal(train_Resampled_16, 270, 16, 13)\n",
    "test_Resampled_16 = normal(test_Resampled_16, 370, 16, 13)\n",
    "# Len = 15:\n",
    "train_Resampled_15 = normal(train_Resampled_15, 270, 15, 13)\n",
    "test_Resampled_15 = normal(test_Resampled_15, 370, 15, 13)\n",
    "# Len = 14: \n",
    "train_Resampled_14 = normal(train_Resampled_14, 270, 14, 13)\n",
    "test_Resampled_14 = normal(test_Resampled_14, 370, 14, 13)\n",
    "# Len = 13:\n",
    "train_Resampled_13 = normal(train_Resampled_13, 270, 13, 13)\n",
    "test_Resampled_13 = normal(test_Resampled_13, 370, 13, 13)\n",
    "# Len = 12:\n",
    "train_Resampled_12 = normal(train_Resampled_12, 270, 12, 13)\n",
    "test_Resampled_12 = normal(test_Resampled_12, 370, 12, 13)\n",
    "# Len = 11:\n",
    "train_Resampled_11 = normal(train_Resampled_11, 270, 11, 13)\n",
    "test_Resampled_11 = normal(test_Resampled_11, 370, 11, 13)\n",
    "# Len = 10: \n",
    "train_Resampled_10 = normal(train_Resampled_10, 270, 10, 13)\n",
    "test_Resampled_10 = normal(test_Resampled_10, 370, 10, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train3D has 17 elements\n",
    "train3D = [train_Resampled_26, train_Resampled_25, train_Resampled_24, train_Resampled_23, train_Resampled_22, train_Resampled_21, train_Resampled_20, train_Resampled_19, train_Resampled_18, train_Resampled_17, train_Resampled_16, train_Resampled_15, train_Resampled_14, train_Resampled_13, train_Resampled_12, train_Resampled_11, train_Resampled_10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping arrays for use with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape Training Data to 2D array for SVM:\n",
    "train_Resampled_26_2D = train_Resampled_26.reshape(270, 338)\n",
    "train_Resampled_25_2D = train_Resampled_25.reshape(270, 325)\n",
    "train_Resampled_24_2D = train_Resampled_24.reshape(270, 312)\n",
    "train_Resampled_23_2D = train_Resampled_23.reshape(270, 299)\n",
    "train_Resampled_22_2D = train_Resampled_22.reshape(270, 286)\n",
    "train_Resampled_21_2D = train_Resampled_21.reshape(270, 273)\n",
    "train_Resampled_20_2D = train_Resampled_20.reshape(270, 260)\n",
    "train_Resampled_19_2D = train_Resampled_19.reshape(270, 247)\n",
    "train_Resampled_18_2D = train_Resampled_18.reshape(270, 234)\n",
    "train_Resampled_17_2D = train_Resampled_17.reshape(270, 221)\n",
    "train_Resampled_16_2D = train_Resampled_16.reshape(270, 208)\n",
    "train_Resampled_15_2D = train_Resampled_15.reshape(270, 195)\n",
    "train_Resampled_14_2D = train_Resampled_14.reshape(270, 182)\n",
    "train_Resampled_13_2D = train_Resampled_13.reshape(270, 169)\n",
    "train_Resampled_12_2D = train_Resampled_12.reshape(270, 156)\n",
    "train_Resampled_11_2D = train_Resampled_11.reshape(270, 143)\n",
    "train_Resampled_10_2D = train_Resampled_10.reshape(270, 130)\n",
    "\n",
    "\n",
    "#this is for umap:\n",
    "test_Resampled_26_2D = test_Resampled_26.reshape(370, 338)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train2D has 17 elements\n",
    "train2D = [train_Resampled_26_2D, train_Resampled_25_2D, train_Resampled_24_2D, train_Resampled_23_2D, train_Resampled_22_2D, train_Resampled_21_2D, train_Resampled_20_2D ,train_Resampled_19_2D, train_Resampled_18_2D, train_Resampled_17_2D, train_Resampled_16_2D, train_Resampled_15_2D, train_Resampled_14_2D, train_Resampled_13_2D, train_Resampled_12_2D, train_Resampled_11_2D, train_Resampled_10_2D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length inputs_train: 216\n",
      "Length outputs_train: 216\n",
      "Length inputs_test: 270\n",
      "Length trainOutputsNew: 270\n"
     ]
    }
   ],
   "source": [
    "# Crossvalidation. Currently only splitting in train-test data. Ideally, we want a validation set as well (e.g. 80 - 10 - 10 or 60 - 20 - 20)\n",
    "# Function taken from my Intro to Data Science assignment 3 code\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def splitData(inputs, outputs):   \n",
    "    # To avoid overfitting, we divide the dataset into a part for training and a part for testing\n",
    "    # We split the dataset into 80% training data and 20% testing data\n",
    "    inputs_train, inputs_test, outputs_train, outputs_test = train_test_split(\n",
    "            inputs, outputs, test_size=0.20) \n",
    "    \n",
    "    return inputs_train, inputs_test, outputs_train, outputs_test\n",
    "\n",
    "inputs_train, inputs_test, outputs_train, outputs_test = splitData(train_Resampled_26, trainOutputsNew)\n",
    "\n",
    "print('Length inputs_train:', len(inputs_train))\n",
    "print('Length outputs_train:', len(outputs_train))\n",
    "print('Length inputs_test:', len(trainOutputsNew))\n",
    "print('Length trainOutputsNew:', len(trainOutputsNew))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Implementation Support Vector Machine\n",
    "def SVM(inputs_train, outputs_train, inputs_test):    \n",
    "    # Create a classifier \n",
    "    classifier = svm.SVC(kernel='linear')    \n",
    "    outputs_train = outputs_train.astype('int')\n",
    "    classifier.fit(inputs_train, outputs_train)\n",
    "    \n",
    "    # Predict the test data\n",
    "    labels_prediction = classifier.predict(inputs_test)\n",
    "\n",
    "    return labels_prediction\n",
    "\n",
    "\n",
    "# Implementation Multilayer Perceptron\n",
    "def MLP(inputs_train, outputs_train, inputs_test):\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(30, 20, 20), \n",
    "                               max_iter=2000, activation = 'relu',solver='adam',random_state=1)\n",
    "    outputs_train = outputs_train.astype('int')\n",
    "    classifier.fit(inputs_train, outputs_train)\n",
    "    \n",
    "    # Predict the test data\n",
    "    labels_prediction = classifier.predict(inputs_test)\n",
    "\n",
    "    return labels_prediction\n",
    "\n",
    "def simpleLogisticRegression(inputs_train, outputs_train, inputs_test):\n",
    "    model = LogisticRegression(max_iter=500)\n",
    "    outputs_train = outputs_train.astype('int')\n",
    "\n",
    "    model.fit(inputs_train, outputs_train)\n",
    "\n",
    "    labels_prediction = model.predict(inputs_test)\n",
    "    #print(labels_prediction)\n",
    "    \n",
    "    return labels_prediction\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "\"\"\" Creates ensemble classifier with our best performing classifiers\"\"\"\n",
    "# Code based on code from assignment of IDS.\n",
    "def createEnsemble():\n",
    "    # Our best performing classifiers\n",
    "    classifier1 = svm.SVC(kernel='linear')  \n",
    "    # classifier2 = LogisticRegression(max_iter=500)\n",
    "    \n",
    "    classifier3 = MLPClassifier(hidden_layer_sizes=(30, 20, 20), \n",
    "                               max_iter=2000, activation = 'relu',solver='adam',random_state=1)\n",
    "    classifier4 = svm.SVC(kernel='poly')\n",
    "    \n",
    "    ensemble = VotingClassifier(estimators = [('SVM_linear', classifier1),  \n",
    "                                              ('mlp', classifier3), ('SVM_poly', classifier4), \n",
    "                                              ], voting = 'hard')\n",
    "    \n",
    "    return ensemble\n",
    "\n",
    "\"\"\" Returns prediction from ensemble classifier\"\"\"   \n",
    "def ensemble(inputs_train, outputs_train, inputs_test):\n",
    "    ensemble = createEnsemble()\n",
    "    ensemble.fit(inputs_train, outputs_train) \n",
    "    \n",
    "    # Predict the test data\n",
    "    labels_prediction = ensemble.predict(inputs_test)\n",
    "    \n",
    "    return labels_prediction\n",
    "\n",
    "\n",
    "def predictLabels(trainInputs, trainOutputs):\n",
    "    inputs_train, inputs_test, outputs_train, outputs_test = splitData(trainInputs, trainOutputs)\n",
    "\n",
    "    # Predict the test labels\n",
    "    prediction = ensemble(inputs_train, outputs_train, inputs_test)\n",
    "\n",
    "    # Print results\n",
    "    wrong = 0\n",
    "    length = len(prediction)\n",
    "    for i in range(length):\n",
    "        #print(prediction[i], np.ravel(outputs_test)[i])\n",
    "        if(prediction[i] != np.ravel(outputs_test)[i]):\n",
    "            wrong = wrong + 1\n",
    "\n",
    "    return ((length - wrong) / length) * 100\n",
    "\n",
    "#print('Go')\n",
    "\n",
    "no_iterations = 1\n",
    "\n",
    "\n",
    "\n",
    "#sampleNum = 26\n",
    "#for data in train2D:\n",
    "    #accuracy_train = np.zeros(no_iterations)\n",
    "    #for i in range(no_iterations):\n",
    "        #accuracy_train = predictLabels(data, trainOutputsNew)\n",
    "    #print(\"Accuracy for {} size arrays: {}\".format(sampleNum, np.mean(accuracy_train)))\n",
    "    #sampleNum = sampleNum - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of SVM Performance on different data preprocessing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_Resampled_26_2D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-aa3c26b15ed0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0maccuracy_PrePad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictLabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPrePadding_2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainOutputsNew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0maccuracy_PostPad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictLabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPostPadding_2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainOutputsNew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0maccuracy_Resampling\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictLabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_Resampled_26_2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainOutputsNew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy Prepadding: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_PrePad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_Resampled_26_2D' is not defined"
     ]
    }
   ],
   "source": [
    "runs = 10\n",
    "\n",
    "accuracy_raw = np.zeros(runs)\n",
    "accuracy_PrePad = np.zeros(runs)\n",
    "accuracy_PostPad = np.zeros(runs)\n",
    "accuracy_Resampling = np.zeros(runs)\n",
    "\n",
    "for i in range(runs):\n",
    "    #accuracy_raw[i] = predictLabels(trainInputs_array, trainOutputs_array)\n",
    "    accuracy_PrePad[i] = predictLabels(PrePadding_2D, trainOutputsNew)\n",
    "    accuracy_PostPad[i] = predictLabels(PostPadding_2D, trainOutputsNew)\n",
    "    accuracy_Resampling[i] = predictLabels(train_Resampled_26_2D, trainOutputsNew)\n",
    "\n",
    "print(\"Accuracy Prepadding: \", np.mean(accuracy_PrePad))\n",
    "print(\"Accuracy Postpadding: \", np.mean(accuracy_PostPad))\n",
    "print(\"Accuracy Resampling: \", np.mean(accuracy_Resampling))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51517925 0.10139663 0.08465458 0.0561965  0.04841669]\n",
      "[0.53511747 0.09688439 0.08101894 0.05409792 0.04648686]\n",
      "[0.5557643  0.09271315 0.07727817 0.05165824 0.04444773]\n",
      "[0.57669834 0.08898482 0.07360015 0.04909003 0.04218898]\n",
      "[0.60209645 0.08307486 0.06978759 0.04608506 0.03964042]\n",
      "[0.62910753 0.07696794 0.06495458 0.04328643 0.03685592]\n"
     ]
    }
   ],
   "source": [
    "# Perform preprocessing: PCA\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Try: all data in one vector\n",
    "trainInputsList = [train_Resampled_26_2D, train_Resampled_24_2D, train_Resampled_22_2D, train_Resampled_20_2D, train_Resampled_18_2D, train_Resampled_16_2D]\n",
    "Outputs = np.reshape(trainOutputsNew, (270,1))\n",
    "for PCAInputs in trainInputsList:\n",
    "    #print(Outputs)\n",
    "    allTrainInputs = np.concatenate([PCAInputs,Outputs],axis=1)\n",
    "    \n",
    "    datasetPCA = pd.DataFrame(allTrainInputs)\n",
    "    \n",
    "    pca = PCA(n_components=5)\n",
    "    pca.fit(datasetPCA)\n",
    "    principalComponents = pca.fit_transform(datasetPCA)\n",
    "\n",
    "    print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variation per principal component: [0.20321894 0.17451443]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(train_Resampled_26_2D)\n",
    "\n",
    "# Prints PCA plot (Does only work with a PCA with 2 components)\n",
    "# Code based on https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
    "principalComponents = pca.fit_transform(train_Resampled_26_2D)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "finalDf = pd.concat([principalDf, pd.DataFrame(Outputs)], axis = 1)\n",
    "#print(finalDf)\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
    "\n",
    "fig = plt.figure(figsize = (12,12))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "# Choose the speakers that you want to visualize in the plot\n",
    "targets = [1, 3, 4]\n",
    "colors = 'r', 'g', 'b'\n",
    "# Uncomment if you want to visualize all speakers\n",
    "#targets = [1,2,3,4,5,6,7,8,9]\n",
    "#colors = ['r', 'g', 'b', 'k', 'c', 'm', 'y', 'tab:orange', 'tab:brown']\n",
    "\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf[0] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reduction & visualisation with UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Reduction with UMAP\n",
    "# pip3 install umap-learn\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "# Installing didn't work on my machine, so I provided tha path manually\n",
    "sys.path.append('/Users/lauridsstockert/opt/anaconda3/lib/python3.7/site-packages')\n",
    "\n",
    "import umap\n",
    "\n",
    "sns.set(style='white', context='poster', rc={'figure.figsize':(14,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def umapCalc(input_data, n_neighbors, n_components, min_dist):\n",
    "    reducer = umap.UMAP(n_neighbors=n_neighbors, n_components = n_components, min_dist = min_dist)\n",
    "    embedding = reducer.fit_transform(input_data)\n",
    "    return embedding\n",
    "\n",
    "def drawUmap(input_data, input_labels, n_neighbors=15, min_dist=0.1, n_components=2, metric='euclidean', title=''):\n",
    "    fit = umap.UMAP(\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        n_components=n_components,\n",
    "        metric=metric\n",
    "    )\n",
    "    u = fit.fit_transform(input_data)\n",
    "    fig = plt.figure()\n",
    "    if n_components == 1:\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.scatter(u[:,0], range(len(u)), c=input_labels)\n",
    "    if n_components == 2:\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.scatter(u[:,0], u[:,1], c=input_labels)\n",
    "    if n_components == 3:\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(u[:,0], u[:,1], u[:,2], c=input_labels, s=100)\n",
    "    if n_components > 3:\n",
    "        print(\"ERROR: Cannot draw more than 3 dimensions\")\n",
    "    plt.title(title, fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying Data Reduction with UMAP\n",
    "# Results range can get as high as 77% (best try so far)\n",
    "# I have commented out the code for parameter optimisation\n",
    "\n",
    "#accuracy_padded_after = np.zeros(100)\n",
    "######accuracy_padded_before = np.zeros(100)\n",
    "#cnt = 1\n",
    "\n",
    "#for n in (2, 5, 10, 20):\n",
    "    #for d in (0.1, 0.2, 0.4):\n",
    "        #for c in (2, 5):\n",
    "            #accuracy_padded_after = np.zeros(100)\n",
    "            #inputs_train_umap = umapCalc(trainInputsSquaredPost, n, c, d)\n",
    "            #for i in range(100):\n",
    "                #accuracy_padded_after[i] = predictLabels(inputs_train_umap, trainOutputsNew)\n",
    "            #print(\"Params are n_neighbors(n), min_dist(d), and n_components(c) \\n  n = {}, d = {}, c = {}\".format(n, d, c))\n",
    "            #print(\"Av. Accuracy (padding after)\", np.mean(accuracy_padded_after))\n",
    "            #print(\"\\n\")\n",
    "            #cnt = cnt + 1\n",
    "# empirically good combinations:\n",
    "# Acc = 77%: n = 50, d = 0.99, c = 7\n",
    "# Acc = 63.37%: n = 20, d = 0.8, c = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in (2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12):\n",
    "    pass\n",
    "    #drawUmap(input_data = trainInputsSquaredPost, input_labels = trainOutputsNew, n_neighbors=n, n_components = 3, title='n_neighbors = {}'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in (0.0, 0.1, 0.25, 0.5, 0.8, 0.99):\n",
    "    pass\n",
    "    #drawUmap(input_data = trainInputsSquaredPost, input_labels = trainOutputsNew, min_dist=d, title='min_dist = {}'.format(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM classifier implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for those packages install tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictLabelsLSTM(trainInputs, trainOutputs, epochs_option, optimizer_option, dropout_option):\n",
    "    inputs_train, inputs_test, outputs_train, outputs_test = splitData(trainInputs, trainOutputs)\n",
    "    \n",
    "    inputs_train = np.asarray(inputs_train).astype('float32')\n",
    "    inputs_test = np.asarray(inputs_test).astype('float32')\n",
    "    outputs_train = np.asarray(outputs_train).astype('float32')\n",
    "    outputs_test = np.asarray(outputs_test).astype('float32')\n",
    "    #choose embedding length that is equal to the amount of dimensions\n",
    "    #embedding_vecor_length = 13\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units = 100, return_sequences = True, input_shape = inputs_train[0])))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_option))\n",
    "    model.add(Bidirectional(LSTM(units = 100)))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer_option, metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    #[print(i.shape, i.dtype) for i in model.inputs]\n",
    "    #[print(o.shape, o.dtype) for o in model.outputs]\n",
    "    #[print(l.name, l.input_shape, l.dtype) for l in model.layers]\n",
    "    \n",
    "    model.fit(inputs_train, outputs_train, epochs=epochs_option, batch_size=4, verbose=0)\n",
    "    \n",
    "    scores = model.evaluate(inputs_test, outputs_test, verbose=0)\n",
    "\n",
    "    return scores[1]*100\n",
    "\n",
    "\n",
    "iterations = 10\n",
    "\n",
    "#sampleNum = 26\n",
    "#for data in train3D:\n",
    "    #accuracy_train = np.zeros(no_iterations)\n",
    "    #for i in range(iterations):\n",
    "        #accuracy_train = predictLabelsLSTM(data, trainOutputsNew)\n",
    "    #print(\"Accuracy for {} size arrays: {}\".format(sampleNum, np.mean(accuracy_train)))\n",
    "    #sampleNum = sampleNum - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 14 ; Optimizer adamax ; Epochs 10 ; Accuracy 95.74074149131775\n",
      "Length 14 ; Optimizer adamax ; Epochs 10 ; Accuracy 95.18518447875977\n",
      "Length 14 ; Optimizer adamax ; Epochs 10 ; Accuracy 95.55555582046509\n",
      "Length 20 ; Optimizer adamax ; Epochs 10 ; Accuracy 96.29629611968994\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-0e84f7eea6c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                     \u001b[0maccuracies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictLabelsLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainOutputsNew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"; Optimizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"; Epochs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"; Accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-7bc35b8e4765>\u001b[0m in \u001b[0;36mpredictLabelsLSTM\u001b[0;34m(trainInputs, trainOutputs, epochs_option, optimizer_option, dropout_option)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#[print(l.name, l.input_shape, l.dtype) for l in model.layers]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs_option\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EpochTimes = [ 10, 15, 20]\n",
    "Optimizers = ['adamax','sgd', 'adagrad']\n",
    "Resamples = [train_Resampled_14, train_Resampled_20, train_Resampled_26]\n",
    "Dropouts = [ 0.1, 0.2, 0.3]\n",
    "\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "iterations = 10\n",
    "for epochs in EpochTimes:\n",
    "    for optimizer in Optimizers:\n",
    "        for sample in Resamples:\n",
    "            for dropout in Dropouts:\n",
    "                accuracies = np.zeros(iterations)\n",
    "                for i in range(iterations):\n",
    "                    accuracies[i] = predictLabelsLSTM(sample, trainOutputsNew, epochs, optimizer, dropout)\n",
    "                print(\"Length\", len(sample[0]), \"; Optimizer\", optimizer, \"; Epochs\", epochs, \"; Dropout\", dropout, \"; Accuracy\", np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_something = np.zeros(iterations)\n",
    "for i in range(iterations):\n",
    "    pass\n",
    "    #accuracy_something[i] = predictLabelsLSTM(train3D[0], trainOutputsNew)\n",
    "#print(\"Accuracy: \", np.mean(accuracy_something))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictLabelsLSTM_test(inputs_train, inputs_test, outputs_train, outputs_test):\n",
    "    \n",
    "    inputs_train = np.asarray(inputs_train).astype('float32')\n",
    "    inputs_test = np.asarray(inputs_test).astype('float32')\n",
    "    outputs_train = np.asarray(outputs_train).astype('float32')\n",
    "    outputs_test = np.asarray(outputs_test).astype('float32')\n",
    "    #choose embedding length that is equal to the amount of dimensions\n",
    "    #embedding_vecor_length = 13\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units = 100, return_sequences = True, input_shape = inputs_train[0])))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(LSTM(units = 100)))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    #[print(i.shape, i.dtype) for i in model.inputs]\n",
    "    #[print(o.shape, o.dtype) for o in model.outputs]\n",
    "    #[print(l.name, l.input_shape, l.dtype) for l in model.layers]\n",
    "    \n",
    "    model.fit(inputs_train, outputs_train, epochs=25, batch_size=4)\n",
    "    \n",
    "    scores = model.evaluate(inputs_test, outputs_test, verbose=0)\n",
    "\n",
    "    return scores[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_iter = 10\n",
    "#test_accuracy = np.zeros(no_iter)\n",
    "\n",
    "for j in range(no_iter):\n",
    "    pass\n",
    "    #test_accuracy[j] = predictLabelsLSTM_test(train_Resampled_26, test_Resampled_26, trainOutputsNew, testOutputsNew)\n",
    "#print(\"Test Accuracy:\", np.mean(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECHO classifier implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Still need to check if 2D data array from before works with ECHO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainOutputsNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Format data for ECHO implenetation\n",
    "ECHO_Train_26 = train_Resampled_26_2D.reshape(7020, 13)\n",
    "\n",
    "trainOutputsEcho = np.zeros((7020, 9))\n",
    "\n",
    "for i in range (270):\n",
    "    for j in range(26):\n",
    "        trainOutputsEcho[i * 26 + j][trainOutputsNew[i] - 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "trainInputs_array = []\n",
    "trainOutputs_array = []\n",
    "\n",
    "for i in range(270):\n",
    "    ndim = np.shape(trainInputs[i][0])[0]\n",
    "    for j in range(ndim):\n",
    "        trainInputs_array.append(trainInputs[i][0][j])\n",
    "        trainOutputs_array.append(trainOutputs[i][0][j])\n",
    "\n",
    "# test data        \n",
    "testInputs_array = []\n",
    "testOutputs_array = []\n",
    "\n",
    "for i in range(370):\n",
    "    ndim = np.shape(testInputs[i][0])[0]\n",
    "    for j in range(ndim):\n",
    "        testInputs_array.append(testInputs[i][0][j])\n",
    "        testOutputs_array.append(testOutputs[i][0][j])\n",
    "    \n",
    "    \n",
    "# data arrays used for ESN; all the timesteps with its 12 channels (dim) in each recording put into a list\n",
    "trainInputs_array = np.asarray(trainInputs_array)     \n",
    "trainOutputs_array = np.asarray(trainOutputs_array)\n",
    "\n",
    "testInputs_array = np.asarray(testInputs_array)\n",
    "testOutputs_array = np.asarray(testOutputs_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from pyESN import ESN\n",
    "\n",
    "esn = ESN(n_inputs = 13,\n",
    "          n_outputs = 9,\n",
    "          n_reservoir = 300,\n",
    "          spectral_radius = 1.5,\n",
    "          random_state=42)\n",
    "\n",
    "# cross validation\n",
    "inputs_train, inputs_test, outputs_train, outputs_test = splitData(ECHO_Train_26, trainOutputsEcho)\n",
    "\n",
    "print(inputs_train.shape)\n",
    "print(outputs_train.shape)\n",
    "print(inputs_test.shape)\n",
    "\n",
    "train_pred, mean_error_train = esn.fit(inputs_train, outputs_train, inspect=True)\n",
    "test_pred = esn.predict(inputs_test)\n",
    "\n",
    "print(\"Mean test error: \", np.mean((test_pred - outputs_test)**2))\n",
    "print(\"Mean training error:\", mean_error_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter optimization + cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esn = ESN(n_inputs = 12,\n",
    "          n_outputs = 9,\n",
    "          random_state=42)\n",
    "\n",
    "# parameter optimization\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=269, n_repeats=2, random_state=42)\n",
    "param_grid = {\"n_reservoir\": [200, 400, 600, 800, 1000]}\n",
    "\n",
    "clf = GridSearchCV(esn, param_grid)\n",
    "\n",
    "m_scores = cross_val_score(esn, trainInputs, trainOutputs, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
