{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Project: Japanese Vowel speaker classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data into time series arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasfortuin/anaconda/lib/python3.6/site-packages/pandas/compat/_optional.py:124: UserWarning: Pandas requires version '1.2.1' or newer of 'bottleneck' (version '1.2.0' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing data sets\n",
    "trainData = np.loadtxt(\"ae.train\")\n",
    "testData = np.loadtxt(\"ae.test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview: \n",
    "* Training: 270 (30 utterances by 9 speakers. See file 'size_ae.train'.) \n",
    "* Testing: 370 (24-88 utterances by the same 9 speakers in different opportunities. See file 'size_ae.test'.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtaining 270 training time series arrays\n",
    "# arrays are (N x 12); where N is length of time series recording and 12 is number of dimensions (ie channels)\n",
    "trainInputs = np.empty((270,1), dtype=object)\n",
    "readindex = 0\n",
    "\n",
    "for i in range(1,271):\n",
    "    readindex = readindex + 1  \n",
    "    l = 0\n",
    "    while trainData[readindex-1, 1] != 1:\n",
    "        l = l + 1 \n",
    "        readindex = readindex + 1\n",
    "    trainInputs[i-1,0] = trainData[readindex-l-1:readindex-1,:]\n",
    "\n",
    "\n",
    "# obtaining 370 test time series arrays \n",
    "# arrays are (N x 12); where N is length of time series recording and 12 is number of dimensions (ie channels)\n",
    "testInputs = np.empty((370,1), dtype=object)\n",
    "readindex = 0\n",
    "\n",
    "# The last 12 entries of each recording are 1s, indicating 12 channels\n",
    "# They are droppped when reading in the data\n",
    "for i in range(1,371):\n",
    "    readindex = readindex + 1\n",
    "    l = 0 \n",
    "    while testData[readindex-1, 1] != 1:\n",
    "        l = l+1 \n",
    "        readindex = readindex + 1\n",
    "    testInputs[i-1,0] = testData[readindex-l-1:readindex-1,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtaining 270 training outputs (speaker targets)\n",
    "# arrays are (N x 9); where N is length of time series recording and 9 is number of different speakers\n",
    "# the speaker is indicated with a '1'\n",
    "trainOutputs = np.empty((270,1), dtype=object)\n",
    "\n",
    "for i in range(1,271):\n",
    "    l = np.size(trainInputs[i-1,0],0)\n",
    "    teacher = np.zeros((l,9))\n",
    "    speakerIndex = np.ceil(i/30)\n",
    "    teacher[:,np.int(speakerIndex)-1] = 1 \n",
    "    trainOutputs[i-1,0] = teacher\n",
    "\n",
    "# obtaining 370 test outputs (speaker targets)\n",
    "# arrays are (N x 9); where N is length of time series recording and 9 is number of different speakers\n",
    "# the speaker is indicated with a '1'\n",
    "testOutputs = np.empty((370,1), dtype=object)\n",
    "speakerIndex = 1\n",
    "blockCounter = 0\n",
    "blockLengthes = [31, 35, 88, 44, 29, 24, 40, 50, 29]\n",
    "for i in range(1, 371):\n",
    "    blockCounter = blockCounter + 1 \n",
    "    if blockCounter == blockLengthes[speakerIndex-1] + 1:\n",
    "        speakerIndex = speakerIndex + 1\n",
    "        blockCounter = 1\n",
    "    l = np.size(testInputs[i-1,0], 0)\n",
    "    teacher = np.zeros((l,9))\n",
    "    teacher[:,np.int(speakerIndex)-1] = 1   \n",
    "    testOutputs[i-1, 0] = teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\n/GZmJePEb2ZWMk78ZmYl8/9A+ZIbXyxtBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prints histogram of timeseries length (exploratory analysis)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "histos = np.zeros(270)\n",
    "\n",
    "for i in range(270):\n",
    "    histos[i] = (len(trainInputs[i, 0]))\n",
    "\n",
    "#print(histos)\n",
    "plt.title('Counting timeseries length (total 270)')\n",
    "plt.xlabel('Timeseries length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(histos, bins = 20, ec='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add length of each recording as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "RecordingLength = histos\n",
    "for i in range(270):\n",
    "    RecordingLength[i] = RecordingLength[i] / 26\n",
    "#print(RecordingLength)\n",
    "\n",
    "for i in range(270):\n",
    "    lenArray = len(trainInputs[i][0])\n",
    "    rec = np.full(lenArray, RecordingLength[i])\n",
    "    newArray = np.column_stack((trainInputs[i][0][:], rec))\n",
    "    trainInputs[i][0] = newArray\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing: Subtract minimum value of channel from each value. Finish with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#according to the paper by Dwarampudi et al 2019(in whatsappchat), prepadding is preferred. \n",
    "#However we seem to get better results with postpadding. That's why both are kept for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First: Find minimum of all channels of all samples\n",
    "minimum = np.zeros(13)\n",
    "for sample in trainInputs:\n",
    "    for array in sample[0]:\n",
    "        channelnumber = 0\n",
    "        for number in array:\n",
    "            if number < minimum[channelnumber]:\n",
    "                minimum[channelnumber] = number\n",
    "            channelnumber = channelnumber + 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.783783 -1.852765 -0.745858 -0.957525 -0.691587 -0.83559  -0.616608\n",
      " -0.57128  -0.623201 -0.503843 -0.426728 -0.336968  0.      ]\n"
     ]
    }
   ],
   "source": [
    "print(minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Subtract minimum value from all values per channel\n",
    "trainInputsNonNegative = copy.deepcopy(trainInputs)\n",
    "samplenumber = 0\n",
    "for sample in trainInputsNonNegative:\n",
    "    arraynumber = 0\n",
    "    for array in sample[0]:\n",
    "        channelnumber = 0\n",
    "        for number in array:\n",
    "            trainInputsNonNegative[samplenumber][0][arraynumber][channelnumber] = number - minimum[channelnumber]\n",
    "            channelnumber = channelnumber + 1\n",
    "        arraynumber = arraynumber + 1\n",
    "    samplenumber = samplenumber + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pads the training inputs with zeroes to make all the timeseries of equal length\n",
    "size_max = 13 * 26\n",
    "trainInputsNonNegativePre = np.empty((270,size_max), dtype=object)\n",
    "trainInputsNonNegativePost = np.empty((270,size_max), dtype=object)\n",
    "\n",
    "idx = 0 \n",
    "for element in trainInputsNonNegative:\n",
    "    element = np.ndarray.flatten(element[0])\n",
    "    # Pads zeroes before    \n",
    "    elements = element\n",
    "    elements = np.pad(elements, (size_max - len(elements), 0), 'constant')\n",
    "    trainInputsNonNegativePre[idx] = elements\n",
    "    \n",
    "    # Pads zeroes after\n",
    "    # Pad element with zeroes until it reaches the shape of the largest timeseries (12 * 26 = 312)\n",
    "    shape = np.shape(element)\n",
    "    padded_array = np.zeros(size_max)\n",
    "    padded_array[:shape[0]] = element  \n",
    "    element = padded_array\n",
    "    # print(element)\n",
    "\n",
    "    trainInputsNonNegativePost[idx] = element\n",
    "    idx = idx + 1\n",
    "\n",
    "trainOutputsNew = np.empty((270,1), dtype=object)\n",
    "\n",
    "# Transforms the trainOutputs in classes 1-9\n",
    "idxx = 0\n",
    "for elements in trainOutputs:\n",
    "    for i in range(len(elements[0][0])):\n",
    "       if elements[0][0][i] == 1:\n",
    "           trainOutputsNew[idxx] = i + 1\n",
    "           idxx = idxx + 1\n",
    "        \n",
    "trainOutputsNew = np.ravel(trainOutputsNew)\n",
    "trainOutputsNew = trainOutputsNew.astype('int')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing 2: Put numbers in range 0-1. Finish with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Additionally set numbers between 0/1\n",
    "#Find maximum per channel\n",
    "trainInputsZeroOne = copy.deepcopy(trainInputsNonNegative)\n",
    "maximum = np.zeros(13)\n",
    "for sample in trainInputs:\n",
    "    for array in sample[0]:\n",
    "        channelnumber = 0\n",
    "        for number in array:\n",
    "            if number > maximum[channelnumber]:\n",
    "                maximum[channelnumber] = number\n",
    "            channelnumber = channelnumber + 1\n",
    "\n",
    "#divide by maximum value per channel\n",
    "samplenumber = 0\n",
    "for sample in trainInputsZeroOne:\n",
    "    arraynumber = 0\n",
    "    for array in sample[0]:\n",
    "        channelnumber = 0\n",
    "        for number in array:\n",
    "            trainInputsZeroOne[samplenumber][0][arraynumber][channelnumber] = number / maximum[channelnumber]\n",
    "            channelnumber = channelnumber + 1\n",
    "        arraynumber = arraynumber + 1\n",
    "    samplenumber = samplenumber + 1\n",
    "\n",
    "#pad the samples\n",
    "size_max = 13 * 26\n",
    "trainInputsZeroOnePre = np.empty((270,size_max), dtype=object)\n",
    "trainInputsZeroOnePost = np.empty((270,size_max), dtype=object)\n",
    "\n",
    "idx = 0 \n",
    "for element in trainInputsZeroOne:\n",
    "    element = np.ndarray.flatten(element[0])\n",
    "    # Pads zeroes before    \n",
    "    elements = element\n",
    "    elements = np.pad(elements, (size_max - len(elements), 0), 'constant')\n",
    "    trainInputsZeroOnePre[idx] = elements\n",
    "    \n",
    "    # Pads zeroes after\n",
    "    # Pad element with zeroes until it reaches the shape of the largest timeseries (13 * 26 = 338)\n",
    "    shape = np.shape(element)\n",
    "    padded_array = np.zeros(size_max)\n",
    "    padded_array[:shape[0]] = element  \n",
    "    element = padded_array\n",
    "\n",
    "    trainInputsZeroOnePost[idx] = element\n",
    "    idx = idx + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing 3: Induce bias by squaring. Finish with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalize/Bias numbers by squaring\n",
    "trainInputsSquared = copy.deepcopy(trainInputsZeroOne)\n",
    "\n",
    "#divide by maximum value per channel\n",
    "samplenumber = 0\n",
    "for sample in trainInputsSquared:\n",
    "    arraynumber = 0\n",
    "    for array in sample[0]:\n",
    "        channelnumber = 0\n",
    "        for number in array:\n",
    "            trainInputsSquared[samplenumber][0][arraynumber][channelnumber] = number *number\n",
    "            channelnumber = channelnumber + 1\n",
    "        arraynumber = arraynumber + 1\n",
    "    samplenumber = samplenumber + 1\n",
    "\n",
    "#pad normalized further samples\n",
    "size_max = 13 * 26\n",
    "trainInputsSquaredPre = np.empty((270,size_max), dtype=object)\n",
    "trainInputsSquaredPost = np.empty((270,size_max), dtype=object)\n",
    "\n",
    "idx = 0 \n",
    "for element in trainInputsSquared:\n",
    "    element = np.ndarray.flatten(element[0])\n",
    "    # Pads zeroes before    \n",
    "    elements = element\n",
    "    elements = np.pad(elements, (size_max - len(elements), 0), 'constant')\n",
    "    trainInputsSquaredPre[idx] = elements\n",
    "    \n",
    "    # Pads zeroes after\n",
    "    # Pad element with zeroes until it reaches the shape of the largest timeseries (13 * 26 = 338)\n",
    "    shape = np.shape(element)\n",
    "    padded_array = np.zeros(size_max)\n",
    "    padded_array[:shape[0]] = element  \n",
    "    element = padded_array\n",
    "\n",
    "    trainInputsSquaredPost[idx] = element\n",
    "    idx = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length inputs_train: 216\n",
      "Length outputs_train: 216\n",
      "Length inputs_test: 270\n",
      "Length trainOutputsNew: 270\n"
     ]
    }
   ],
   "source": [
    "# Crossvalidation. Currently only splitting in train-test data. Ideally, we want a validation set as well (e.g. 80 - 10 - 10 or 60 - 20 - 20)\n",
    "# Function taken from my Intro to Data Science assignment 3 code\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def splitData(inputs, outputs):   \n",
    "    # To avoid overfitting, we divide the dataset into a part for training and a part for testing\n",
    "    # We split the dataset into 80% training data and 20% testing data\n",
    "    inputs_train, inputs_test, outputs_train, outputs_test = train_test_split(\n",
    "            inputs, outputs, test_size=0.20) \n",
    "    \n",
    "    return inputs_train, inputs_test, outputs_train, outputs_test\n",
    "\n",
    "inputs_train, inputs_test, outputs_train, outputs_test = splitData(trainInputsNonNegative, trainOutputsNew)\n",
    "\n",
    "print('Length inputs_train:', len(inputs_train))\n",
    "print('Length outputs_train:', len(outputs_train))\n",
    "print('Length inputs_test:', len(trainOutputsNew))\n",
    "print('Length trainOutputsNew:', len(trainOutputsNew))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy NonNegativePre: 93.1666666666667\n",
      "Average accuracy NonNegativePost: 93.79629629629633\n",
      "Average accuracy ZeroOnePre: 94.00000000000004\n",
      "Average accuracy ZeroOnePost: 91.98148148148151\n",
      "Average accuracy SquaredPre: 90.96296296296298\n",
      "Average accuracy SquaredPost: 88.07407407407409\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Implementation Support Vector Machine\n",
    "def SVM(inputs_train, outputs_train, inputs_test):    \n",
    "    # Create a classifier \n",
    "    classifier = svm.SVC(kernel='linear')    \n",
    "    outputs_train = outputs_train.astype('int')\n",
    "    classifier.fit(inputs_train, outputs_train)\n",
    "    \n",
    "    # Predict the test data\n",
    "    labels_prediction = classifier.predict(inputs_test)\n",
    "\n",
    "    return labels_prediction\n",
    "\n",
    "def predictLabels(trainInputs, trainOutputs):\n",
    "    inputs_train, inputs_test, outputs_train, outputs_test = splitData(trainInputs, trainOutputs)\n",
    "\n",
    "    # Predict the test labels\n",
    "    prediction = SVM(inputs_train, outputs_train, inputs_test)\n",
    "\n",
    "    # Print results\n",
    "    wrong = 0\n",
    "    length = len(prediction)\n",
    "    for i in range(length):\n",
    "        #print(prediction[i], np.ravel(outputs_test)[i])\n",
    "        if(prediction[i] != np.ravel(outputs_test)[i]):\n",
    "            wrong = wrong + 1\n",
    "\n",
    "    return ((length - wrong) / length) * 100\n",
    "\n",
    "#Pre is for prepadded, Post for postpadded\n",
    "accuracy_NonNegativePre = np.zeros(100)\n",
    "accuracy_NonNegativePost = np.zeros(100)\n",
    "accuracy_ZeroOnePre = np.zeros(100)\n",
    "accuracy_ZeroOnePost = np.zeros(100)\n",
    "accuracy_SquaredPre = np.zeros(100)\n",
    "accuracy_SquaredPost = np.zeros(100)\n",
    "for j in range(100):\n",
    "    accuracy_NonNegativePre[j] = predictLabels(trainInputsNonNegativePre, trainOutputsNew)\n",
    "    accuracy_NonNegativePost[j] = predictLabels(trainInputsNonNegativePost, trainOutputsNew)\n",
    "    accuracy_ZeroOnePre[j] = predictLabels(trainInputsZeroOnePre, trainOutputsNew)\n",
    "    accuracy_ZeroOnePost[j] = predictLabels(trainInputsZeroOnePost, trainOutputsNew)\n",
    "    accuracy_SquaredPre[j] = predictLabels(trainInputsSquaredPre, trainOutputsNew)\n",
    "    accuracy_SquaredPost[j] = predictLabels(trainInputsSquaredPost, trainOutputsNew)\n",
    "    \n",
    "print(\"Average accuracy NonNegativePre:\", np.mean(accuracy_NonNegativePre))\n",
    "print(\"Average accuracy NonNegativePost:\", np.mean(accuracy_NonNegativePost))\n",
    "print(\"Average accuracy ZeroOnePre:\", np.mean(accuracy_ZeroOnePre))\n",
    "print(\"Average accuracy ZeroOnePost:\", np.mean(accuracy_ZeroOnePost))\n",
    "print(\"Average accuracy SquaredPre:\", np.mean(accuracy_SquaredPre))\n",
    "print(\"Average accuracy SquaredPost:\", np.mean(accuracy_SquaredPost))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3255768  0.17684966 0.10279152 0.08734447 0.05666658]\n",
      "[0.32259331 0.18185452 0.09971127 0.08574962 0.05633363]\n",
      "[0.32957766 0.11031341 0.0962252  0.08014898 0.05482995]\n",
      "[0.34802061 0.11580156 0.0901371  0.07660845 0.05427013]\n",
      "[0.26853369 0.19097212 0.10633549 0.06034419 0.03827272]\n",
      "[0.30407787 0.15645354 0.12452489 0.06535366 0.03582739]\n"
     ]
    }
   ],
   "source": [
    "# Perform preprocessing: PCA\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Try: all data in one vector\n",
    "trainInputsList = [trainInputsNonNegativePre, trainInputsNonNegativePost, trainInputsZeroOnePre, trainInputsZeroOnePost, trainInputsSquaredPre, trainInputsSquaredPost]\n",
    "Outputs = np.reshape(trainOutputsNew, (270,1))\n",
    "for PCAInputs in trainInputsList:\n",
    "    #print(Outputs)\n",
    "    allTrainInputs = np.concatenate([PCAInputs,Outputs],axis=1)\n",
    "    \n",
    "    datasetPCA = pd.DataFrame(allTrainInputs)\n",
    "    \n",
    "    pca = PCA(n_components=5)\n",
    "    pca.fit(datasetPCA)\n",
    "    principalComponents = pca.fit_transform(datasetPCA)\n",
    "\n",
    "    print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variation per principal component: [0.37461664 0.1290972 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasfortuin/anaconda/lib/python3.6/site-packages/pandas/compat/_optional.py:124: UserWarning: Pandas requires version '2.6.2' or newer of 'numexpr' (version '2.6.1' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAALTCAYAAAA2KJVIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(trainInputsNonNegativePre)\n",
    "\n",
    "# Prints PCA plot (Does only work with a PCA with 2 components)\n",
    "# Code based on https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
    "principalComponents = pca.fit_transform(trainInputsNonNegativePre)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "finalDf = pd.concat([principalDf, pd.DataFrame(Outputs)], axis = 1)\n",
    "#print(finalDf)\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
    "\n",
    "fig = plt.figure(figsize = (12,12))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "# Choose the speakers that you want to visualize in the plot\n",
    "targets = [1, 3, 4]\n",
    "colors = 'r', 'g', 'b'\n",
    "# Uncomment if you want to visualize all speakers\n",
    "#targets = [1,2,3,4,5,6,7,8,9]\n",
    "#colors = ['r', 'g', 'b', 'k', 'c', 'm', 'y', 'tab:orange', 'tab:brown']\n",
    "\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf[0] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM with different Data structure\n",
    "from sklearn import svm\n",
    "\n",
    "# Implementation Support Vector Machine\n",
    "def SVM_alt(inputs_train, outputs_train, inputs_test):    \n",
    "    # Create a classifier \n",
    "    classifier = svm.SVC(kernel='linear')    \n",
    "    outputs_train = outputs_train.astype('int')\n",
    "    classifier.fit(inputs_train, outputs_train)\n",
    "    \n",
    "    # Predict the test data\n",
    "    labels_prediction = classifier.predict(inputs_test)\n",
    "\n",
    "    return labels_prediction\n",
    "\n",
    "def predictLabels_alt(inputs_train, inputs_test, outputs_train, outputs_test):\n",
    "    #inputs_train, inputs_test, outputs_train, outputs_test = splitData(trainInputs, trainOutputs)\n",
    "\n",
    "    # Predict the test labels\n",
    "    prediction = SVM_alt(inputs_train, outputs_train, inputs_test)\n",
    "\n",
    "    # Print results\n",
    "    wrong = 0\n",
    "    length = len(prediction)\n",
    "    for i in range(length):\n",
    "        #print(prediction[i], np.ravel(outputs_test)[i])\n",
    "        if(prediction[i] != np.ravel(outputs_test)[i]):\n",
    "            wrong = wrong + 1\n",
    "\n",
    "    return ((length - wrong) / length) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'susi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1147beeee7bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/lauridsstockert/opt/anaconda3/lib/python3.7/site-packages'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msusi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# Same Problem as with UMAP. Will work for you without this line I think.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'susi'"
     ]
    }
   ],
   "source": [
    "# Data Reduction with Self-organising maps (SOM)\n",
    "# The results are pretty depressing\n",
    "# pip3 install susi\n",
    "import sys\n",
    "sys.path.append('/Users/lauridsstockert/opt/anaconda3/lib/python3.7/site-packages')\n",
    "\n",
    "import susi\n",
    "# Same Problem as with UMAP. Will work for you without this line I think.\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {\n",
    "    \"n_rows\": [5, 10, 20],\n",
    "    \"n_columns\": [5, 20, 40],\n",
    "    \"learning_rate_start\": [0.5, 0.7, 0.9],\n",
    "    \"learning_rate_end\": [0.1, 0.05, 0.005],\n",
    "}\n",
    "som = susi.SOMClustering()\n",
    "#clf = RandomizedSearchCV(som, param_grid, random_state=1)\n",
    "#clf.fit(inputs_train)\n",
    "#print(clf.best_params_)\n",
    "inputs_train_som = som.fit_transform(inputs_train)\n",
    "inputs_test_som = som.fit_transform(inputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    accuracy_padded_after[i] = predictLabels_alt(inputs_train_som, inputs_test_som, outputs_train, outputs_test)\n",
    "print(\"Av. Accuracy (padding after)\", np.mean(accuracy_padded_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Reduction with UMAP\n",
    "# The results are equally depressing\n",
    "# pip3 install umap-learn\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "# Installing didn't work on my machine, so I provided tha path manually\n",
    "sys.path.append('/Users/lauridsstockert/opt/anaconda3/lib/python3.7/site-packages')\n",
    "\n",
    "import umap\n",
    "\n",
    "sns.set(style='white', context='poster', rc={'figure.figsize':(14,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def umapFun(input_data, n_neighbors, n_components, min_dist):\n",
    "    reducer = umap.UMAP(n_neighbors=n_neighbors, n_components = n_components, min_dist = min_dist)\n",
    "    embedding = reducer.fit_transform(input_data)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trying Data Reduction with UMAP\n",
    "# The results are depressing\n",
    "accuracy_padded_after = np.zeros(100)\n",
    "#accuracy_padded_before = np.zeros(100)\n",
    "cnt = 1\n",
    "\n",
    "for n in (2, 5, 10, 20, 50, 100, 200):\n",
    "    for d in (0.8, 0.99):\n",
    "        for c in (2, 7):\n",
    "            accuracy_padded_after = np.zeros(100)\n",
    "            inputs_train_umap = umapFun(inputs_train, n, c, d)\n",
    "            inputs_test_umap = umapFun(inputs_test, n, c, d)\n",
    "            for i in range(100):\n",
    "                accuracy_padded_after[i] = predictLabels_alt(inputs_train_umap, inputs_test_umap, outputs_train , outputs_test)\n",
    "            print(\"cnt:\", cnt)\n",
    "            print(\"Av. Accuracy (padding after)\", np.mean(accuracy_padded_after))\n",
    "            cnt = cnt + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECHO classifier implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,12) and (13,) not aligned: 12 (dim 1) != 13 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-775b1e9e1762>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainInputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m      \u001b[0;31m# state vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainOutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_error_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mesn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtrain_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_error_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomasfortuin/Desktop/Machine Learning/GIT2/Jap_Speak_Recog/pyESN.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, outputs, inspect)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             states[n, :] = self._update(states[n - 1], inputs_scaled[n, :],\n\u001b[0;32m--> 181\u001b[0;31m                                         teachers_scaled[n - 1, :])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# learn the weights, i.e. find the linear combination of collected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomasfortuin/Desktop/Machine Learning/GIT2/Jap_Speak_Recog/pyESN.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, state, input_pattern, output_pattern)\u001b[0m\n\u001b[1;32m    118\u001b[0m             preactivation = (np.dot(self.W, state)\n\u001b[1;32m    119\u001b[0m                              \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                              + np.dot(self.W_feedb, output_pattern))\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             preactivation = (np.dot(self.W, state)\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,12) and (13,) not aligned: 12 (dim 1) != 13 (dim 0)"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from pyESN import ESN\n",
    "\n",
    "esn = ESN(n_inputs = 12,\n",
    "          n_outputs = 9,\n",
    "          n_reservoir = 2,\n",
    "          spectral_radius = 1.5,\n",
    "          random_state=42)\n",
    "\n",
    "train_error = []\n",
    "\n",
    "for i in range(270):\n",
    "    sample = trainInputs[i][0]      # state vector\n",
    "    output = trainOutputs[i][0]\n",
    "    train_pred, train_error_sample = esn.fit(sample, output)\n",
    "    train_error.append(train_error_sample)\n",
    "\n",
    "x = esn.fit(trainInputs, trainOutputsNew)\n",
    "    \n",
    "test_error = []\n",
    "\n",
    "for i in range(370):\n",
    "    test_pred = esn.predict(testInputs[i][0])\n",
    "    test_error_sample = np.sqrt(np.mean((test_pred - testOutputs[i][0])**2))\n",
    "    test_error.append(test_error_sample)\n",
    "    \n",
    "print(\"Mean training error (RMSE):\")   # root-mean-square-error\n",
    "print(np.mean(train_error))\n",
    "print(\"Mean test error (RMSE):\")\n",
    "print(np.mean(test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter optimization + cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "If no scoring is specified, the estimator passed should have a 'score' method. The estimator <pyESN.ESN object at 0x7f91f332d518> does not.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-49d58874a11d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mesn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mm_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mesn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainInputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainOutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/thomasfortuin/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomasfortuin/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \"\"\"\n\u001b[1;32m    398\u001b[0m     \u001b[0;31m# To ensure multimetric format is not supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n",
      "\u001b[0;32m/Users/thomasfortuin/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomasfortuin/anaconda/lib/python3.6/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0;34m\"If no scoring is specified, the estimator passed should \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m                 \u001b[0;34m\"have a 'score' method. The estimator %r does not.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 % estimator)\n\u001b[0m\u001b[1;32m    429\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         raise ValueError(\"For evaluating multiple scores, use \"\n",
      "\u001b[0;31mTypeError\u001b[0m: If no scoring is specified, the estimator passed should have a 'score' method. The estimator <pyESN.ESN object at 0x7f91f332d518> does not."
     ]
    }
   ],
   "source": [
    "esn = ESN(n_inputs = 12,\n",
    "          n_outputs = 9,\n",
    "          random_state=42)\n",
    "\n",
    "# parameter optimization\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=269, n_repeats=2, random_state=42)\n",
    "param_grid = {\"n_reservoir\": [200, 400, 600, 800, 1000]}\n",
    "\n",
    "clf = GridSearchCV(esn, param_grid)\n",
    "\n",
    "m_scores = cross_val_score(esn, trainInputs, trainOutputs, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
